{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "252e97bc-2c33-4ff8-a8c6-ee3c494e69aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DAY 20: CLOUD DEPLOYMENT WITH HUGGING FACE SPACES\n",
      "================================================================================\n",
      "üìÖ Date: November 15, 2025\n",
      "üéØ Goal: Deploy MediScan to the cloud\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "==================================================\n",
    "ML LEARNING JOURNEY - DAY 20\n",
    "==================================================\n",
    "Week: 3 of 25\n",
    "Day: 20 of 175\n",
    "Date: November 15, 2025\n",
    "Topic: Cloud Deployment with Hugging Face Spaces\n",
    "Overall Progress: 11.4%\n",
    "\n",
    "Week 3 Progress:\n",
    "‚úÖ Day 15: Dataset Exploration (COMPLETE!)\n",
    "‚úÖ Day 16: Baseline CNN - 94.16% (COMPLETE!)\n",
    "‚úÖ Day 17: Transfer Learning - 94.48% (COMPLETE!)\n",
    "‚úÖ Day 18: Grad-CAM Visualization (COMPLETE!)\n",
    "‚úÖ Day 19: Web Deployment (COMPLETE!)\n",
    "‚úÖ Day 20: Cloud Deployment (COMPLETE!)\n",
    "‚¨ú Day 21: Documentation & Polish\n",
    "\n",
    "Progress: 86% (6/7 days)\n",
    "\n",
    "==================================================\n",
    "üéØ Week 3 Project: MediScan - Medical X-Ray Classifier\n",
    "- Deployed to Hugging Face Spaces\n",
    "- Globally accessible web application\n",
    "- Public URL with Gradio interface\n",
    "\n",
    "üéØ Today's Accomplishments:\n",
    "1. Created separate deployment repository\n",
    "2. Converted Streamlit app to Gradio\n",
    "3. Deployed to Hugging Face Spaces\n",
    "4. Configured Python environment and dependencies\n",
    "5. Uploaded trained model (90MB)\n",
    "6. Tested live deployment with real X-rays\n",
    "7. Updated GitHub README with live demo link\n",
    "\n",
    "üìö Today's Focus:\n",
    "   Part 1: Deployment Platform Selection\n",
    "   Part 2: Code Conversion (Streamlit ‚Üí Gradio)\n",
    "   Part 3: Hugging Face Spaces Setup\n",
    "   Part 4: Testing & Validation\n",
    "\n",
    "üéØ SUCCESS CRITERIA:\n",
    "   ‚úÖ App deployed to cloud\n",
    "   ‚úÖ Public URL accessible worldwide\n",
    "   ‚úÖ Working predictions with Grad-CAM\n",
    "   ‚úÖ Fast inference time (<5 seconds)\n",
    "   ‚úÖ Professional appearance\n",
    "   ‚úÖ Updated documentation\n",
    "\n",
    "==================================================\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DAY 20: CLOUD DEPLOYMENT WITH HUGGING FACE SPACES\")\n",
    "print(\"=\" * 80)\n",
    "print(\"üìÖ Date: November 15, 2025\")\n",
    "print(\"üéØ Goal: Deploy MediScan to the cloud\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87759a29-a760-4030-a41d-2039effac154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DAY 20: CLOUD DEPLOYMENT WITH HUGGING FACE SPACES\n",
      "================================================================================\n",
      "üìÖ Date: November 16, 2025\n",
      "üéØ Goal: Deploy MediScan to the cloud\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "==================================================\n",
    "ML LEARNING JOURNEY - DAY 20\n",
    "==================================================\n",
    "Week: 3 of 25\n",
    "Day: 20 of 175\n",
    "Date: November 16, 2025\n",
    "Topic: Cloud Deployment with Hugging Face Spaces\n",
    "Overall Progress: 11.4%\n",
    "\n",
    "Week 3 Progress:\n",
    "‚úÖ Day 15: Dataset Exploration (COMPLETE!)\n",
    "‚úÖ Day 16: Baseline CNN - 94.16% (COMPLETE!)\n",
    "‚úÖ Day 17: Transfer Learning - 94.48% (COMPLETE!)\n",
    "‚úÖ Day 18: Grad-CAM Visualization (COMPLETE!)\n",
    "‚úÖ Day 19: Web Deployment (COMPLETE!)\n",
    "‚úÖ Day 20: Cloud Deployment (COMPLETE!)\n",
    "‚¨ú Day 21: Documentation & Polish\n",
    "\n",
    "Progress: 86% (6/7 days)\n",
    "\n",
    "==================================================\n",
    "üéØ Week 3 Project: MediScan - Medical X-Ray Classifier\n",
    "- Deployed to Hugging Face Spaces\n",
    "- Globally accessible web application\n",
    "- Public URL with Gradio interface\n",
    "\n",
    "üéØ Today's Accomplishments:\n",
    "1. Created separate deployment repository\n",
    "2. Converted Streamlit app to Gradio\n",
    "3. Deployed to Hugging Face Spaces\n",
    "4. Configured Python environment and dependencies\n",
    "5. Uploaded trained model (90MB)\n",
    "6. Tested live deployment with real X-rays\n",
    "7. Updated GitHub README with live demo link\n",
    "\n",
    "üìö Today's Focus:\n",
    "   Part 1: Deployment Platform Selection\n",
    "   Part 2: Code Conversion (Streamlit ‚Üí Gradio)\n",
    "   Part 3: Hugging Face Spaces Setup\n",
    "   Part 4: Testing & Validation\n",
    "\n",
    "üéØ SUCCESS CRITERIA:\n",
    "   ‚úÖ App deployed to cloud\n",
    "   ‚úÖ Public URL accessible worldwide\n",
    "   ‚úÖ Working predictions with Grad-CAM\n",
    "   ‚úÖ Fast inference time (<5 seconds)\n",
    "   ‚úÖ Professional appearance\n",
    "   ‚úÖ Updated documentation\n",
    "\n",
    "==================================================\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DAY 20: CLOUD DEPLOYMENT WITH HUGGING FACE SPACES\")\n",
    "print(\"=\" * 80)\n",
    "print(\"üìÖ Date: November 16, 2025\")\n",
    "print(\"üéØ Goal: Deploy MediScan to the cloud\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5757230-c674-4a4d-a7ab-2ee2c74a0d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ü§î WHY HUGGING FACE SPACES?\n",
      "================================================================================\n",
      "\n",
      "DEPLOYMENT OPTIONS CONSIDERED:\n",
      "\n",
      "1. Streamlit Community Cloud\n",
      "   ‚ùå Python 3.13 compatibility issues\n",
      "   ‚ùå PyTorch version conflicts\n",
      "   ‚ùå Build kept failing\n",
      "   ‚è±Ô∏è Time wasted: 1+ hour\n",
      "\n",
      "2. Hugging Face Spaces ‚úÖ (CHOSEN)\n",
      "   ‚úÖ Excellent for ML/AI apps\n",
      "   ‚úÖ Built-in Gradio support\n",
      "   ‚úÖ Free tier with GPU option\n",
      "   ‚úÖ Easy deployment process\n",
      "   ‚úÖ Great community visibility\n",
      "   ‚úÖ Works perfectly with PyTorch\n",
      "\n",
      "DECISION: Hugging Face Spaces\n",
      "- Better suited for ML applications\n",
      "- Streamlit had too many compatibility issues\n",
      "- Gradio is simpler and more reliable\n",
      "- 5-minute deployment vs hours of debugging\n",
      "\n",
      "BENEFITS OF HUGGING FACE SPACES:\n",
      "‚úÖ Free hosting with CPU\n",
      "‚úÖ Automatic HTTPS and scaling\n",
      "‚úÖ Built-in community features\n",
      "‚úÖ Perfect for ML/AI portfolios\n",
      "‚úÖ Easy integration with Hugging Face Hub\n",
      "‚úÖ Popular in ML community\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ü§î WHY HUGGING FACE SPACES?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "DEPLOYMENT OPTIONS CONSIDERED:\n",
    "\n",
    "1. Streamlit Community Cloud\n",
    "   ‚ùå Python 3.13 compatibility issues\n",
    "   ‚ùå PyTorch version conflicts\n",
    "   ‚ùå Build kept failing\n",
    "   ‚è±Ô∏è Time wasted: 1+ hour\n",
    "\n",
    "2. Hugging Face Spaces ‚úÖ (CHOSEN)\n",
    "   ‚úÖ Excellent for ML/AI apps\n",
    "   ‚úÖ Built-in Gradio support\n",
    "   ‚úÖ Free tier with GPU option\n",
    "   ‚úÖ Easy deployment process\n",
    "   ‚úÖ Great community visibility\n",
    "   ‚úÖ Works perfectly with PyTorch\n",
    "\n",
    "DECISION: Hugging Face Spaces\n",
    "- Better suited for ML applications\n",
    "- Streamlit had too many compatibility issues\n",
    "- Gradio is simpler and more reliable\n",
    "- 5-minute deployment vs hours of debugging\n",
    "\n",
    "BENEFITS OF HUGGING FACE SPACES:\n",
    "‚úÖ Free hosting with CPU\n",
    "‚úÖ Automatic HTTPS and scaling\n",
    "‚úÖ Built-in community features\n",
    "‚úÖ Perfect for ML/AI portfolios\n",
    "‚úÖ Easy integration with Hugging Face Hub\n",
    "‚úÖ Popular in ML community\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f4c2443-f20a-4e78-8f51-d5ad0c24bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üîÑ STREAMLIT ‚Üí GRADIO CONVERSION\n",
      "================================================================================\n",
      "\n",
      "KEY DIFFERENCES:\n",
      "\n",
      "STREAMLIT:\n",
      "- More complex state management\n",
      "- Requires @st.cache_resource\n",
      "- Custom CSS with st.markdown()\n",
      "- File uploader: st.file_uploader()\n",
      "- Button: st.button()\n",
      "- Multi-column layout: st.columns()\n",
      "\n",
      "GRADIO:\n",
      "- Simpler event handling\n",
      "- Automatic caching\n",
      "- Built-in themes\n",
      "- File input: gr.Image()\n",
      "- Button: gr.Button()\n",
      "- Row/Column: gr.Row(), gr.Column()\n",
      "\n",
      "CONVERSION PROCESS:\n",
      "\n",
      "1. Replace Streamlit imports with Gradio\n",
      "   - streamlit ‚Üí gradio\n",
      "\n",
      "2. Convert UI components\n",
      "   - st.file_uploader() ‚Üí gr.Image()\n",
      "   - st.button() ‚Üí gr.Button()\n",
      "   - st.image() ‚Üí gr.Image()\n",
      "   - st.markdown() ‚Üí gr.Markdown()\n",
      "\n",
      "3. Restructure layout\n",
      "   - Remove st.set_page_config()\n",
      "   - Use gr.Blocks() context\n",
      "   - Define inputs/outputs clearly\n",
      "\n",
      "4. Connect functionality\n",
      "   - button.click(fn=predict, inputs=..., outputs=...)\n",
      "\n",
      "5. Remove Streamlit-specific features\n",
      "   - No @st.cache_resource needed\n",
      "   - No session state required\n",
      "   - Simpler callback structure\n",
      "\n",
      "RESULT: Cleaner, simpler code with same functionality!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üîÑ STREAMLIT ‚Üí GRADIO CONVERSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "KEY DIFFERENCES:\n",
    "\n",
    "STREAMLIT:\n",
    "- More complex state management\n",
    "- Requires @st.cache_resource\n",
    "- Custom CSS with st.markdown()\n",
    "- File uploader: st.file_uploader()\n",
    "- Button: st.button()\n",
    "- Multi-column layout: st.columns()\n",
    "\n",
    "GRADIO:\n",
    "- Simpler event handling\n",
    "- Automatic caching\n",
    "- Built-in themes\n",
    "- File input: gr.Image()\n",
    "- Button: gr.Button()\n",
    "- Row/Column: gr.Row(), gr.Column()\n",
    "\n",
    "CONVERSION PROCESS:\n",
    "\n",
    "1. Replace Streamlit imports with Gradio\n",
    "   - streamlit ‚Üí gradio\n",
    "   \n",
    "2. Convert UI components\n",
    "   - st.file_uploader() ‚Üí gr.Image()\n",
    "   - st.button() ‚Üí gr.Button()\n",
    "   - st.image() ‚Üí gr.Image()\n",
    "   - st.markdown() ‚Üí gr.Markdown()\n",
    "   \n",
    "3. Restructure layout\n",
    "   - Remove st.set_page_config()\n",
    "   - Use gr.Blocks() context\n",
    "   - Define inputs/outputs clearly\n",
    "   \n",
    "4. Connect functionality\n",
    "   - button.click(fn=predict, inputs=..., outputs=...)\n",
    "   \n",
    "5. Remove Streamlit-specific features\n",
    "   - No @st.cache_resource needed\n",
    "   - No session state required\n",
    "   - Simpler callback structure\n",
    "\n",
    "RESULT: Cleaner, simpler code with same functionality!\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43b25b42-bc35-4ad6-a9f4-b0ee300549af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üöÄ DEPLOYMENT PROCESS\n",
      "================================================================================\n",
      "\n",
      "STEP-BY-STEP DEPLOYMENT:\n",
      "\n",
      "1. CREATED SEPARATE REPOSITORY\n",
      "   - Repository: mediscan-ai\n",
      "   - Clean structure (no learning notebooks)\n",
      "   - Professional README\n",
      "   - Portfolio-ready presentation\n",
      "\n",
      "2. CREATED HUGGING FACE ACCOUNT\n",
      "   - Signed up at huggingface.co\n",
      "   - Verified email\n",
      "   - Connected to GitHub\n",
      "\n",
      "3. CREATED NEW SPACE\n",
      "   - Name: mediscan-ai\n",
      "   - SDK: Gradio\n",
      "   - Hardware: CPU (free tier)\n",
      "   - License: MIT\n",
      "   - Visibility: Public\n",
      "\n",
      "4. UPLOADED FILES\n",
      "   Files uploaded:\n",
      "   ‚îú‚îÄ‚îÄ app.py (Gradio interface)\n",
      "   ‚îú‚îÄ‚îÄ requirements.txt (dependencies)\n",
      "   ‚îú‚îÄ‚îÄ models/resnet50_best.pth (trained model, 90MB)\n",
      "   ‚îî‚îÄ‚îÄ README.md (documentation)\n",
      "\n",
      "5. CONFIGURED DEPENDENCIES\n",
      "   requirements.txt:\n",
      "   - gradio==4.44.0\n",
      "   - torch==2.1.0\n",
      "   - torchvision==0.16.0\n",
      "   - Pillow==10.0.0\n",
      "   - opencv-python-headless==4.8.0.76\n",
      "   - numpy==1.24.3\n",
      "\n",
      "6. WAITED FOR BUILD\n",
      "   - Hugging Face installed dependencies\n",
      "   - Built Docker container\n",
      "   - Started Gradio app\n",
      "   - Build time: ~5 minutes\n",
      "\n",
      "7. TESTED DEPLOYMENT\n",
      "   - Uploaded NORMAL X-ray ‚Üí 94.84% confidence ‚úÖ\n",
      "   - Uploaded PNEUMONIA X-ray ‚Üí 99.47% confidence ‚úÖ\n",
      "   - Grad-CAM working perfectly ‚úÖ\n",
      "   - Inference time: ~2-3 seconds ‚úÖ\n",
      "\n",
      "8. UPDATED DOCUMENTATION\n",
      "   - Updated GitHub README\n",
      "   - Added live demo link\n",
      "   - Added deployment badges\n",
      "   - Documented tech stack\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üöÄ DEPLOYMENT PROCESS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "STEP-BY-STEP DEPLOYMENT:\n",
    "\n",
    "1. CREATED SEPARATE REPOSITORY\n",
    "   - Repository: mediscan-ai\n",
    "   - Clean structure (no learning notebooks)\n",
    "   - Professional README\n",
    "   - Portfolio-ready presentation\n",
    "\n",
    "2. CREATED HUGGING FACE ACCOUNT\n",
    "   - Signed up at huggingface.co\n",
    "   - Verified email\n",
    "   - Connected to GitHub\n",
    "\n",
    "3. CREATED NEW SPACE\n",
    "   - Name: mediscan-ai\n",
    "   - SDK: Gradio\n",
    "   - Hardware: CPU (free tier)\n",
    "   - License: MIT\n",
    "   - Visibility: Public\n",
    "\n",
    "4. UPLOADED FILES\n",
    "   Files uploaded:\n",
    "   ‚îú‚îÄ‚îÄ app.py (Gradio interface)\n",
    "   ‚îú‚îÄ‚îÄ requirements.txt (dependencies)\n",
    "   ‚îú‚îÄ‚îÄ models/resnet50_best.pth (trained model, 90MB)\n",
    "   ‚îî‚îÄ‚îÄ README.md (documentation)\n",
    "\n",
    "5. CONFIGURED DEPENDENCIES\n",
    "   requirements.txt:\n",
    "   - gradio==4.44.0\n",
    "   - torch==2.1.0\n",
    "   - torchvision==0.16.0\n",
    "   - Pillow==10.0.0\n",
    "   - opencv-python-headless==4.8.0.76\n",
    "   - numpy==1.24.3\n",
    "\n",
    "6. WAITED FOR BUILD\n",
    "   - Hugging Face installed dependencies\n",
    "   - Built Docker container\n",
    "   - Started Gradio app\n",
    "   - Build time: ~5 minutes\n",
    "\n",
    "7. TESTED DEPLOYMENT\n",
    "   - Uploaded NORMAL X-ray ‚Üí 94.84% confidence ‚úÖ\n",
    "   - Uploaded PNEUMONIA X-ray ‚Üí 99.47% confidence ‚úÖ\n",
    "   - Grad-CAM working perfectly ‚úÖ\n",
    "   - Inference time: ~2-3 seconds ‚úÖ\n",
    "\n",
    "8. UPDATED DOCUMENTATION\n",
    "   - Updated GitHub README\n",
    "   - Added live demo link\n",
    "   - Added deployment badges\n",
    "   - Documented tech stack\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76076a5b-7bb5-4a99-ae53-f271c1409b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "‚öôÔ∏è TECHNICAL CONFIGURATION\n",
      "================================================================================\n",
      "\n",
      "DEPLOYMENT STACK:\n",
      "\n",
      "Platform: Hugging Face Spaces\n",
      "Framework: Gradio 4.44.0\n",
      "Runtime: Python 3.10\n",
      "Hardware: CPU Basic (free tier)\n",
      "Container: Docker\n",
      "Server: Uvicorn\n",
      "\n",
      "MODEL DEPLOYMENT:\n",
      "- Model file: resnet50_best.pth (89.99 MB)\n",
      "- Loaded once at startup (cached)\n",
      "- CPU inference mode\n",
      "- No GPU required\n",
      "- Average inference: 2-3 seconds\n",
      "\n",
      "FILE STRUCTURE:\n",
      "mediscan-ai/\n",
      "‚îú‚îÄ‚îÄ app.py                 # Gradio interface (7.66 KB)\n",
      "‚îú‚îÄ‚îÄ models/\n",
      "‚îÇ   ‚îî‚îÄ‚îÄ resnet50_best.pth # Trained model (89.99 MB)\n",
      "‚îú‚îÄ‚îÄ requirements.txt       # Dependencies (109 bytes)\n",
      "‚îî‚îÄ‚îÄ README.md             # Documentation (300 bytes)\n",
      "\n",
      "GRADIO INTERFACE COMPONENTS:\n",
      "- gr.Image() for X-ray upload\n",
      "- gr.Button() for analysis trigger\n",
      "- gr.Markdown() for results display\n",
      "- gr.Row() and gr.Column() for layout\n",
      "- gr.Blocks() for custom interface\n",
      "\n",
      "FEATURES IMPLEMENTED:\n",
      "‚úÖ File upload (PNG, JPG, JPEG)\n",
      "‚úÖ Real-time prediction\n",
      "‚úÖ Confidence scores\n",
      "‚úÖ Grad-CAM heatmaps\n",
      "‚úÖ Three-panel visualization\n",
      "‚úÖ Professional styling\n",
      "‚úÖ Medical disclaimer\n",
      "‚úÖ Model information\n",
      "\n",
      "PUBLIC URL:\n",
      "https://huggingface.co/spaces/01-Audrey/mediscan-ai\n",
      "\n",
      "GITHUB REPOSITORY:\n",
      "https://github.com/01-Audrey/mediscan-ai\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚öôÔ∏è TECHNICAL CONFIGURATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "DEPLOYMENT STACK:\n",
    "\n",
    "Platform: Hugging Face Spaces\n",
    "Framework: Gradio 4.44.0\n",
    "Runtime: Python 3.10\n",
    "Hardware: CPU Basic (free tier)\n",
    "Container: Docker\n",
    "Server: Uvicorn\n",
    "\n",
    "MODEL DEPLOYMENT:\n",
    "- Model file: resnet50_best.pth (89.99 MB)\n",
    "- Loaded once at startup (cached)\n",
    "- CPU inference mode\n",
    "- No GPU required\n",
    "- Average inference: 2-3 seconds\n",
    "\n",
    "FILE STRUCTURE:\n",
    "mediscan-ai/\n",
    "‚îú‚îÄ‚îÄ app.py                 # Gradio interface (7.66 KB)\n",
    "‚îú‚îÄ‚îÄ models/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ resnet50_best.pth # Trained model (89.99 MB)\n",
    "‚îú‚îÄ‚îÄ requirements.txt       # Dependencies (109 bytes)\n",
    "‚îî‚îÄ‚îÄ README.md             # Documentation (300 bytes)\n",
    "\n",
    "GRADIO INTERFACE COMPONENTS:\n",
    "- gr.Image() for X-ray upload\n",
    "- gr.Button() for analysis trigger\n",
    "- gr.Markdown() for results display\n",
    "- gr.Row() and gr.Column() for layout\n",
    "- gr.Blocks() for custom interface\n",
    "\n",
    "FEATURES IMPLEMENTED:\n",
    "‚úÖ File upload (PNG, JPG, JPEG)\n",
    "‚úÖ Real-time prediction\n",
    "‚úÖ Confidence scores\n",
    "‚úÖ Grad-CAM heatmaps\n",
    "‚úÖ Three-panel visualization\n",
    "‚úÖ Professional styling\n",
    "‚úÖ Medical disclaimer\n",
    "‚úÖ Model information\n",
    "\n",
    "PUBLIC URL:\n",
    "https://huggingface.co/spaces/01-Audrey/mediscan-ai\n",
    "\n",
    "GITHUB REPOSITORY:\n",
    "https://github.com/01-Audrey/mediscan-ai\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7b81a3e-0190-4ad4-aab5-3010933e0b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üí° CHALLENGES & SOLUTIONS\n",
      "================================================================================\n",
      "\n",
      "CHALLENGE 1: Streamlit Cloud Python 3.13 Issues\n",
      "‚ùå Problem: PyTorch versions incompatible with Python 3.13\n",
      "‚ùå Tried: Multiple requirements.txt configurations\n",
      "‚ùå Tried: Adding runtime.txt to force Python 3.11\n",
      "‚ùå Result: Kept failing after 1+ hour\n",
      "‚úÖ Solution: Switched to Hugging Face Spaces with Gradio\n",
      "\n",
      "CHALLENGE 2: Model File Size (90MB)\n",
      "‚ùå Problem: Large file for git\n",
      "‚ö†Ô∏è Warning: GitHub warned about 50MB+ file\n",
      "‚úÖ Solution: Uploaded directly to Hugging Face (handles large files)\n",
      "\n",
      "CHALLENGE 3: Example Images Not Working\n",
      "‚ùå Problem: gr.Examples() causing errors\n",
      "‚ùå Tried: Uploaded example X-rays to examples/ folder\n",
      "‚ùå Result: Still showing errors when clicked\n",
      "‚úÖ Solution: Removed examples section entirely\n",
      "\n",
      "CHALLENGE 4: Understanding Hugging Face Interface\n",
      "‚ùå Problem: First time using Hugging Face Spaces\n",
      "‚ùå Confusion: .gitkeep file, folder structure\n",
      "‚úÖ Solution: Simplified approach - direct file uploads\n",
      "\n",
      "LESSONS LEARNED:\n",
      "\n",
      "1. PLATFORM MATTERS\n",
      "   - Not all platforms work equally for ML apps\n",
      "   - Hugging Face is optimized for ML/AI\n",
      "   - Sometimes switching platforms is faster than debugging\n",
      "\n",
      "2. GRADIO > STREAMLIT FOR DEPLOYMENT\n",
      "   - Simpler interface definition\n",
      "   - Better ML deployment support\n",
      "   - Less configuration needed\n",
      "   - Faster builds\n",
      "\n",
      "3. KEEP IT SIMPLE\n",
      "   - Examples section not necessary\n",
      "   - Users can upload their own images\n",
      "   - Simpler = fewer bugs\n",
      "\n",
      "4. DOCUMENTATION IS KEY\n",
      "   - Clear README helps users\n",
      "   - Deployment badges add credibility\n",
      "   - Live demo links are essential\n",
      "\n",
      "TIME INVESTMENT:\n",
      "- Streamlit attempts: 1+ hour (failed)\n",
      "- Hugging Face setup: 30 minutes\n",
      "- Code conversion: 20 minutes\n",
      "- Testing & polish: 30 minutes\n",
      "- Total: ~2.5 hours (but worth it!)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üí° CHALLENGES & SOLUTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "CHALLENGE 1: Streamlit Cloud Python 3.13 Issues\n",
    "‚ùå Problem: PyTorch versions incompatible with Python 3.13\n",
    "‚ùå Tried: Multiple requirements.txt configurations\n",
    "‚ùå Tried: Adding runtime.txt to force Python 3.11\n",
    "‚ùå Result: Kept failing after 1+ hour\n",
    "‚úÖ Solution: Switched to Hugging Face Spaces with Gradio\n",
    "\n",
    "CHALLENGE 2: Model File Size (90MB)\n",
    "‚ùå Problem: Large file for git\n",
    "‚ö†Ô∏è Warning: GitHub warned about 50MB+ file\n",
    "‚úÖ Solution: Uploaded directly to Hugging Face (handles large files)\n",
    "\n",
    "CHALLENGE 3: Example Images Not Working\n",
    "‚ùå Problem: gr.Examples() causing errors\n",
    "‚ùå Tried: Uploaded example X-rays to examples/ folder\n",
    "‚ùå Result: Still showing errors when clicked\n",
    "‚úÖ Solution: Removed examples section entirely\n",
    "\n",
    "CHALLENGE 4: Understanding Hugging Face Interface\n",
    "‚ùå Problem: First time using Hugging Face Spaces\n",
    "‚ùå Confusion: .gitkeep file, folder structure\n",
    "‚úÖ Solution: Simplified approach - direct file uploads\n",
    "\n",
    "LESSONS LEARNED:\n",
    "\n",
    "1. PLATFORM MATTERS\n",
    "   - Not all platforms work equally for ML apps\n",
    "   - Hugging Face is optimized for ML/AI\n",
    "   - Sometimes switching platforms is faster than debugging\n",
    "\n",
    "2. GRADIO > STREAMLIT FOR DEPLOYMENT\n",
    "   - Simpler interface definition\n",
    "   - Better ML deployment support\n",
    "   - Less configuration needed\n",
    "   - Faster builds\n",
    "\n",
    "3. KEEP IT SIMPLE\n",
    "   - Examples section not necessary\n",
    "   - Users can upload their own images\n",
    "   - Simpler = fewer bugs\n",
    "\n",
    "4. DOCUMENTATION IS KEY\n",
    "   - Clear README helps users\n",
    "   - Deployment badges add credibility\n",
    "   - Live demo links are essential\n",
    "\n",
    "TIME INVESTMENT:\n",
    "- Streamlit attempts: 1+ hour (failed)\n",
    "- Hugging Face setup: 30 minutes\n",
    "- Code conversion: 20 minutes\n",
    "- Testing & polish: 30 minutes\n",
    "- Total: ~2.5 hours (but worth it!)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e39a152-cddd-441d-83d2-0ba71c8dae61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "üß™ DEPLOYMENT TESTING\n",
      "================================================================================\n",
      "\n",
      "TEST 1: NORMAL X-RAY\n",
      "   Input: NORMAL chest X-ray\n",
      "   Prediction: NORMAL ‚úÖ\n",
      "   Confidence: 94.84%\n",
      "   NORMAL probability: 94.84%\n",
      "   PNEUMONIA probability: 5.16%\n",
      "   Inference time: ~2.5 seconds\n",
      "   Grad-CAM: Distributed attention across lungs ‚úÖ\n",
      "   Status: PASSED ‚úÖ\n",
      "\n",
      "TEST 2: PNEUMONIA X-RAY  \n",
      "   Input: PNEUMONIA chest X-ray\n",
      "   Prediction: PNEUMONIA ‚úÖ\n",
      "   Confidence: 99.47%\n",
      "   NORMAL probability: 0.53%\n",
      "   PNEUMONIA probability: 99.47%\n",
      "   Inference time: ~2.3 seconds\n",
      "   Grad-CAM: Focused on infiltrates ‚úÖ\n",
      "   Status: PASSED ‚úÖ\n",
      "\n",
      "TEST 3: MULTIPLE UPLOADS\n",
      "   - Uploaded 5 different X-rays\n",
      "   - All processed successfully\n",
      "   - No crashes or errors\n",
      "   - Consistent inference times\n",
      "   Status: PASSED ‚úÖ\n",
      "\n",
      "TEST 4: MOBILE RESPONSIVENESS\n",
      "   - Tested on mobile browser\n",
      "   - Interface adapts well\n",
      "   - Upload works on mobile\n",
      "   - Images display correctly\n",
      "   Status: PASSED ‚úÖ\n",
      "\n",
      "TEST 5: GRAD-CAM VISUALIZATION\n",
      "   - Original X-ray displays ‚úÖ\n",
      "   - Heatmap generates correctly ‚úÖ\n",
      "   - Overlay combines properly ‚úÖ\n",
      "   - Colors intuitive (red=high, blue=low) ‚úÖ\n",
      "   Status: PASSED ‚úÖ\n",
      "\n",
      "PERFORMANCE METRICS:\n",
      "- Average inference time: 2-3 seconds\n",
      "- Success rate: 100%\n",
      "- Uptime: 100% (so far)\n",
      "- Load time: <2 seconds\n",
      "- Mobile compatible: YES\n",
      "- HTTPS secure: YES\n",
      "\n",
      "PUBLIC ACCESSIBILITY:\n",
      "‚úÖ App accessible worldwide\n",
      "‚úÖ No authentication required\n",
      "‚úÖ Works on all browsers\n",
      "‚úÖ Shareable URL\n",
      "‚úÖ SEO-friendly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üß™ DEPLOYMENT TESTING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "TEST 1: NORMAL X-RAY\n",
    "   Input: NORMAL chest X-ray\n",
    "   Prediction: NORMAL ‚úÖ\n",
    "   Confidence: 94.84%\n",
    "   NORMAL probability: 94.84%\n",
    "   PNEUMONIA probability: 5.16%\n",
    "   Inference time: ~2.5 seconds\n",
    "   Grad-CAM: Distributed attention across lungs ‚úÖ\n",
    "   Status: PASSED ‚úÖ\n",
    "\n",
    "TEST 2: PNEUMONIA X-RAY  \n",
    "   Input: PNEUMONIA chest X-ray\n",
    "   Prediction: PNEUMONIA ‚úÖ\n",
    "   Confidence: 99.47%\n",
    "   NORMAL probability: 0.53%\n",
    "   PNEUMONIA probability: 99.47%\n",
    "   Inference time: ~2.3 seconds\n",
    "   Grad-CAM: Focused on infiltrates ‚úÖ\n",
    "   Status: PASSED ‚úÖ\n",
    "\n",
    "TEST 3: MULTIPLE UPLOADS\n",
    "   - Uploaded 5 different X-rays\n",
    "   - All processed successfully\n",
    "   - No crashes or errors\n",
    "   - Consistent inference times\n",
    "   Status: PASSED ‚úÖ\n",
    "\n",
    "TEST 4: MOBILE RESPONSIVENESS\n",
    "   - Tested on mobile browser\n",
    "   - Interface adapts well\n",
    "   - Upload works on mobile\n",
    "   - Images display correctly\n",
    "   Status: PASSED ‚úÖ\n",
    "\n",
    "TEST 5: GRAD-CAM VISUALIZATION\n",
    "   - Original X-ray displays ‚úÖ\n",
    "   - Heatmap generates correctly ‚úÖ\n",
    "   - Overlay combines properly ‚úÖ\n",
    "   - Colors intuitive (red=high, blue=low) ‚úÖ\n",
    "   Status: PASSED ‚úÖ\n",
    "\n",
    "PERFORMANCE METRICS:\n",
    "- Average inference time: 2-3 seconds\n",
    "- Success rate: 100%\n",
    "- Uptime: 100% (so far)\n",
    "- Load time: <2 seconds\n",
    "- Mobile compatible: YES\n",
    "- HTTPS secure: YES\n",
    "\n",
    "PUBLIC ACCESSIBILITY:\n",
    "‚úÖ App accessible worldwide\n",
    "‚úÖ No authentication required\n",
    "‚úÖ Works on all browsers\n",
    "‚úÖ Shareable URL\n",
    "‚úÖ SEO-friendly\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "284aec8a-e79b-4031-a319-0e1a5622ec9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DAY 20 COMPLETE! ‚úÖ\n",
      "================================================================================\n",
      "\n",
      "OBJECTIVES ACHIEVED:\n",
      "   ‚úÖ Deployed to Hugging Face Spaces\n",
      "   ‚úÖ Converted Streamlit to Gradio\n",
      "   ‚úÖ Created clean deployment repository\n",
      "   ‚úÖ Uploaded trained model (90MB)\n",
      "   ‚úÖ Configured dependencies correctly\n",
      "   ‚úÖ Tested with real X-ray images\n",
      "   ‚úÖ Updated GitHub documentation\n",
      "   ‚úÖ Public URL live and accessible\n",
      "\n",
      "üåê LIVE DEPLOYMENT:\n",
      "   URL: https://huggingface.co/spaces/01-Audrey/mediscan-ai\n",
      "   Status: ‚úÖ LIVE AND RUNNING\n",
      "   Accessibility: üåç Worldwide\n",
      "   Platform: Hugging Face Spaces\n",
      "   Framework: Gradio 4.44.0\n",
      "\n",
      "üì¶ DEPLOYMENT FEATURES:\n",
      "   ‚Ä¢ Real-time chest X-ray classification\n",
      "   ‚Ä¢ NORMAL vs PNEUMONIA detection\n",
      "   ‚Ä¢ 94.48% accuracy model\n",
      "   ‚Ä¢ Grad-CAM explainable AI\n",
      "   ‚Ä¢ Professional medical interface\n",
      "   ‚Ä¢ 2-3 second inference time\n",
      "   ‚Ä¢ Mobile-friendly design\n",
      "\n",
      "üéØ WHAT WE LEARNED:\n",
      "   1. Platform selection matters for ML deployment\n",
      "   2. Hugging Face Spaces > Streamlit for ML apps\n",
      "   3. Gradio is simpler than Streamlit\n",
      "   4. Separate repos for learning vs deployment\n",
      "   5. Documentation and README are crucial\n",
      "   6. Testing on real data validates deployment\n",
      "   7. Sometimes switching platforms saves time\n",
      "\n",
      "üíª TECHNICAL STACK:\n",
      "   ‚Ä¢ Platform: Hugging Face Spaces\n",
      "   ‚Ä¢ Framework: Gradio 4.44.0\n",
      "   ‚Ä¢ ML Framework: PyTorch 2.1.0\n",
      "   ‚Ä¢ Model: ResNet50 Transfer Learning\n",
      "   ‚Ä¢ Visualization: Grad-CAM\n",
      "   ‚Ä¢ Runtime: Python 3.10\n",
      "   ‚Ä¢ Container: Docker\n",
      "   ‚Ä¢ Deployment: Automatic from git push\n",
      "\n",
      "üìö REPOSITORIES:\n",
      "   Deployment: https://github.com/01-Audrey/mediscan-ai\n",
      "   Learning: https://github.com/01-Audrey/ml-learning-lab\n",
      "\n",
      "üéØ NEXT STEPS (DAY 21):\n",
      "   - Create comprehensive Week 3 documentation\n",
      "   - Polish all notebooks\n",
      "   - Add final README to week3 folder\n",
      "   - Take screenshots for portfolio\n",
      "   - Update LinkedIn with project\n",
      "   - Prepare for Week 4\n",
      "\n",
      "üíæ FILES CREATED:\n",
      "   - mediscan-ai/app.py (Gradio interface)\n",
      "   - mediscan-ai/requirements.txt\n",
      "   - mediscan-ai/README.md\n",
      "   - day20_cloud_deployment.ipynb (this notebook)\n",
      "\n",
      "üèÜ WEEK 3 PROGRESS:\n",
      "   ‚úÖ Day 15: Dataset Exploration\n",
      "   ‚úÖ Day 16: Baseline CNN (94.16%)\n",
      "   ‚úÖ Day 17: Transfer Learning (94.48%)\n",
      "   ‚úÖ Day 18: Grad-CAM Visualization\n",
      "   ‚úÖ Day 19: Web Deployment (Local)\n",
      "   ‚úÖ Day 20: Cloud Deployment (COMPLETE!)\n",
      "   ‚¨ú Day 21: Documentation\n",
      "\n",
      "   Progress: 86% (6/7 days)\n",
      "\n",
      "üéâ MILESTONE ACHIEVED:\n",
      "   FIRST EVER CLOUD-DEPLOYED ML APPLICATION!\n",
      "\n",
      "   From idea to production in ONE WEEK:\n",
      "   - Day 15: Started with raw dataset\n",
      "   - Day 16: Built baseline model\n",
      "   - Day 17: Improved with transfer learning\n",
      "   - Day 18: Added explainability\n",
      "   - Day 19: Created web interface\n",
      "   - Day 20: DEPLOYED TO THE WORLD! üåç\n",
      "\n",
      "   This is a COMPLETE end-to-end ML project:\n",
      "   ‚úÖ Data exploration\n",
      "   ‚úÖ Model training\n",
      "   ‚úÖ Visualization\n",
      "   ‚úÖ Web deployment\n",
      "   ‚úÖ Cloud hosting\n",
      "   ‚úÖ Documentation\n",
      "   ‚úÖ Portfolio-ready\n",
      "\n",
      "================================================================================\n",
      "‚ú® My app is live for the world to see!\n",
      "üåê : https://huggingface.co/spaces/01-Audrey/mediscan-ai\n",
      "‚≠ê One more day (Day 21) to complete Week 3!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DAY 20 COMPLETE! ‚úÖ\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "OBJECTIVES ACHIEVED:\n",
    "   ‚úÖ Deployed to Hugging Face Spaces\n",
    "   ‚úÖ Converted Streamlit to Gradio\n",
    "   ‚úÖ Created clean deployment repository\n",
    "   ‚úÖ Uploaded trained model (90MB)\n",
    "   ‚úÖ Configured dependencies correctly\n",
    "   ‚úÖ Tested with real X-ray images\n",
    "   ‚úÖ Updated GitHub documentation\n",
    "   ‚úÖ Public URL live and accessible\n",
    "\n",
    "üåê LIVE DEPLOYMENT:\n",
    "   URL: https://huggingface.co/spaces/01-Audrey/mediscan-ai\n",
    "   Status: ‚úÖ LIVE AND RUNNING\n",
    "   Accessibility: üåç Worldwide\n",
    "   Platform: Hugging Face Spaces\n",
    "   Framework: Gradio 4.44.0\n",
    "\n",
    "üì¶ DEPLOYMENT FEATURES:\n",
    "   ‚Ä¢ Real-time chest X-ray classification\n",
    "   ‚Ä¢ NORMAL vs PNEUMONIA detection\n",
    "   ‚Ä¢ 94.48% accuracy model\n",
    "   ‚Ä¢ Grad-CAM explainable AI\n",
    "   ‚Ä¢ Professional medical interface\n",
    "   ‚Ä¢ 2-3 second inference time\n",
    "   ‚Ä¢ Mobile-friendly design\n",
    "\n",
    "üéØ WHAT WE LEARNED:\n",
    "   1. Platform selection matters for ML deployment\n",
    "   2. Hugging Face Spaces > Streamlit for ML apps\n",
    "   3. Gradio is simpler than Streamlit\n",
    "   4. Separate repos for learning vs deployment\n",
    "   5. Documentation and README are crucial\n",
    "   6. Testing on real data validates deployment\n",
    "   7. Sometimes switching platforms saves time\n",
    "\n",
    "üíª TECHNICAL STACK:\n",
    "   ‚Ä¢ Platform: Hugging Face Spaces\n",
    "   ‚Ä¢ Framework: Gradio 4.44.0\n",
    "   ‚Ä¢ ML Framework: PyTorch 2.1.0\n",
    "   ‚Ä¢ Model: ResNet50 Transfer Learning\n",
    "   ‚Ä¢ Visualization: Grad-CAM\n",
    "   ‚Ä¢ Runtime: Python 3.10\n",
    "   ‚Ä¢ Container: Docker\n",
    "   ‚Ä¢ Deployment: Automatic from git push\n",
    "\n",
    "üìö REPOSITORIES:\n",
    "   Deployment: https://github.com/01-Audrey/mediscan-ai\n",
    "   Learning: https://github.com/01-Audrey/ml-learning-lab\n",
    "\n",
    "üéØ NEXT STEPS (DAY 21):\n",
    "   - Create comprehensive Week 3 documentation\n",
    "   - Polish all notebooks\n",
    "   - Add final README to week3 folder\n",
    "   - Take screenshots for portfolio\n",
    "   - Update LinkedIn with project\n",
    "   - Prepare for Week 4\n",
    "\n",
    "üíæ FILES CREATED:\n",
    "   - mediscan-ai/app.py (Gradio interface)\n",
    "   - mediscan-ai/requirements.txt\n",
    "   - mediscan-ai/README.md\n",
    "   - day20_cloud_deployment.ipynb (this notebook)\n",
    "\n",
    "üèÜ WEEK 3 PROGRESS:\n",
    "   ‚úÖ Day 15: Dataset Exploration\n",
    "   ‚úÖ Day 16: Baseline CNN (94.16%)\n",
    "   ‚úÖ Day 17: Transfer Learning (94.48%)\n",
    "   ‚úÖ Day 18: Grad-CAM Visualization\n",
    "   ‚úÖ Day 19: Web Deployment (Local)\n",
    "   ‚úÖ Day 20: Cloud Deployment (COMPLETE!)\n",
    "   ‚¨ú Day 21: Documentation\n",
    "   \n",
    "   Progress: 86% (6/7 days)\n",
    "\n",
    "üéâ MILESTONE ACHIEVED:\n",
    "   FIRST EVER CLOUD-DEPLOYED ML APPLICATION!\n",
    "   \n",
    "   From idea to production in ONE WEEK:\n",
    "   - Day 15: Started with raw dataset\n",
    "   - Day 16: Built baseline model\n",
    "   - Day 17: Improved with transfer learning\n",
    "   - Day 18: Added explainability\n",
    "   - Day 19: Created web interface\n",
    "   - Day 20: DEPLOYED TO THE WORLD! üåç\n",
    "   \n",
    "   This is a COMPLETE end-to-end ML project:\n",
    "   ‚úÖ Data exploration\n",
    "   ‚úÖ Model training\n",
    "   ‚úÖ Visualization\n",
    "   ‚úÖ Web deployment\n",
    "   ‚úÖ Cloud hosting\n",
    "   ‚úÖ Documentation\n",
    "   ‚úÖ Portfolio-ready\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚ú® My app is live for the world to see!\")\n",
    "print(\"üåê : https://huggingface.co/spaces/01-Audrey/mediscan-ai\")\n",
    "print(\"‚≠ê One more day (Day 21) to complete Week 3!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0f5af6-9869-4a9c-86a9-14c4828798db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
