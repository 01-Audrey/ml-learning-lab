{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c127235-df3e-4802-9165-95e02ecff400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DAY 22: SECURITY SYSTEM - PROJECT PLANNING & ARCHITECTURE\n",
      "================================================================================\n",
      "ğŸ“… Date: November 17, 2025\n",
      "ğŸ¯ Goal: Design and plan 3-week AI security system\n",
      "ğŸ”’ Project: Complete surveillance system with tracking & recognition\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "==================================================\n",
    "ML LEARNING JOURNEY - DAY 22\n",
    "==================================================\n",
    "Week: 4 of 24\n",
    "Day: 22 of 168\n",
    "Date: November 17, 2025\n",
    "Topic: Security System - Project Planning & Architecture\n",
    "Overall Progress: 13.1%\n",
    "\n",
    "WEEKS 4-6: MAJOR PROJECT #1\n",
    "ğŸ”’ AI SECURITY & SURVEILLANCE SYSTEM\n",
    "\n",
    "Week 4: Detection & Tracking Foundation\n",
    "âœ… Day 22: Project Planning & Architecture (TODAY!)\n",
    "â¬œ Day 23: Multi-Object Tracking (DeepSORT)\n",
    "â¬œ Day 24: Tracking Optimization\n",
    "â¬œ Day 25: Video Processing Pipeline\n",
    "â¬œ Day 26: Testing & Performance\n",
    "â¬œ Day 27: Code Cleanup & Modularization\n",
    "â¬œ Day 28: Week 4 Review\n",
    "\n",
    "Week 4 Progress: 14% (1/7 days)\n",
    "\n",
    "==================================================\n",
    "ğŸ¯ 3-WEEK PROJECT OVERVIEW:\n",
    "\n",
    "WEEK 4 (Nov 18-24): Detection & Tracking Foundation\n",
    "- Multi-object tracking with DeepSORT\n",
    "- Real-time processing (30 FPS target)\n",
    "- People counting system\n",
    "- Re-identification across frames\n",
    "\n",
    "WEEK 5 (Nov 25 - Dec 1): Face Recognition & Alerts\n",
    "- Face detection and recognition\n",
    "- Alert system (email, SMS)\n",
    "- Safety violation detection (PPE from Week 2!)\n",
    "- Database for known faces\n",
    "\n",
    "WEEK 6 (Dec 2-8): Dashboard, API & Deployment\n",
    "- REST API with FastAPI\n",
    "- Real-time monitoring dashboard\n",
    "- Analytics and visualizations\n",
    "- Docker deployment\n",
    "- Complete system integration\n",
    "\n",
    "==================================================\n",
    "ğŸ¯ TODAY'S GOALS (DAY 22):\n",
    "\n",
    "1. Design complete system architecture\n",
    "2. Review YOLOv8 from Week 2\n",
    "3. Plan 3-week development roadmap\n",
    "4. Setup project structure\n",
    "5. Test YOLO on video streams\n",
    "6. Understand tracking requirements\n",
    "\n",
    "SUCCESS CRITERIA:\n",
    "âœ… Architecture diagram documented\n",
    "âœ… YOLOv8 reviewed and tested\n",
    "âœ… Project plan clear for 3 weeks\n",
    "âœ… Ready to start tracking (Day 23)\n",
    "\n",
    "==================================================\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DAY 22: SECURITY SYSTEM - PROJECT PLANNING & ARCHITECTURE\")\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“… Date: November 17, 2025\")\n",
    "print(\"ğŸ¯ Goal: Design and plan 3-week AI security system\")\n",
    "print(\"ğŸ”’ Project: Complete surveillance system with tracking & recognition\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764f5ea9-4780-47b7-a076-6dcb6ceabe57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ”’ AI SECURITY & SURVEILLANCE SYSTEM - PROJECT VISION\n",
      "================================================================================\n",
      "\n",
      "PROJECT NAME: SecureVision AI\n",
      "Tagline: Intelligent surveillance that sees, tracks, and protects\n",
      "\n",
      "==================================================\n",
      "\n",
      "WHAT I'M GOING TO BUILD:\n",
      "\n",
      "A complete, production-ready AI security system that combines:\n",
      "âœ“ Real-time object detection (YOLO)\n",
      "âœ“ Multi-object tracking (DeepSORT)\n",
      "âœ“ Face recognition (FaceNet/DeepFace)\n",
      "âœ“ Automated alert system\n",
      "âœ“ Analytics dashboard\n",
      "âœ“ REST API for integration\n",
      "âœ“ Multi-camera support\n",
      "\n",
      "This is NOT just another detector!\n",
      "This is an INTEGRATED SYSTEM showing end-to-end ML engineering.\n",
      "\n",
      "==================================================\n",
      "\n",
      "REAL-WORLD USE CASES:\n",
      "\n",
      "ğŸ¢ OFFICE BUILDINGS\n",
      "   - Track employee movements\n",
      "   - Detect unauthorized access\n",
      "   - Monitor restricted areas\n",
      "   - Attendance tracking\n",
      "\n",
      "ğŸ­ MANUFACTURING FACILITIES\n",
      "   - Safety equipment compliance (PPE detection!)\n",
      "   - Worker count in dangerous zones\n",
      "   - Hazard area monitoring\n",
      "   - Incident detection\n",
      "\n",
      "ğŸª RETAIL STORES\n",
      "   - Customer traffic analysis\n",
      "   - Heat map generation\n",
      "   - Queue management\n",
      "   - Theft detection\n",
      "\n",
      "ğŸ« EDUCATIONAL INSTITUTIONS\n",
      "   - Campus security\n",
      "   - Attendance monitoring\n",
      "   - Visitor management\n",
      "   - Emergency response\n",
      "\n",
      "ğŸ  RESIDENTIAL SECURITY\n",
      "   - Recognize family vs strangers\n",
      "   - Package delivery alerts\n",
      "   - Unusual activity detection\n",
      "   - Remote monitoring\n",
      "\n",
      "==================================================\n",
      "\n",
      "WHY THIS PROJECT IS SPECIAL:\n",
      "\n",
      "1. REAL-TIME PROCESSING\n",
      "   Target: 30 FPS on standard hardware\n",
      "   Challenge: Multiple ML models in pipeline\n",
      "\n",
      "2. MULTIPLE ML COMPONENTS\n",
      "   - Detection (YOLO)\n",
      "   - Tracking (DeepSORT)\n",
      "   - Recognition (FaceNet)\n",
      "   - Classification (PPE)\n",
      "\n",
      "3. STATE MANAGEMENT\n",
      "   - Track objects across frames\n",
      "   - Maintain IDs through occlusions\n",
      "   - Handle multi-camera scenarios\n",
      "\n",
      "4. PRODUCTION-READY\n",
      "   - REST API\n",
      "   - Database integration\n",
      "   - Deployment with Docker\n",
      "   - Monitoring and logging\n",
      "\n",
      "5. PORTFOLIO IMPACT\n",
      "   This demonstrates:\n",
      "   âœ“ System design skills\n",
      "   âœ“ Real-time ML\n",
      "   âœ“ Integration expertise\n",
      "   âœ“ Production engineering\n",
      "   âœ“ Full-stack ML development\n",
      "\n",
      "==================================================\n",
      "\n",
      "TECHNICAL COMPLEXITY:\n",
      "\n",
      "More complex than Week 3 (Medical Classifier):\n",
      "- Video processing vs single images\n",
      "- State management across frames\n",
      "- Multiple ML models integrated\n",
      "- Real-time performance requirements\n",
      "- Multi-component system\n",
      "\n",
      "But I'm READY! I already:\n",
      "âœ… Built YOLO detector (Week 2)\n",
      "âœ… Trained deep learning models (Week 3)\n",
      "âœ… Deployed web applications (Week 2 3)\n",
      "âœ… Handled complex pipelines\n",
      "\n",
      "This brings EVERYTHING together! ğŸ”¥\n",
      "\n",
      "==================================================\n",
      "\n",
      "PROJECT SCOPE - 3 WEEKS:\n",
      "\n",
      "WEEK 4: Build the foundation\n",
      "   Days 22-28: Detection + Tracking working at 30 FPS\n",
      "\n",
      "WEEK 5: Add intelligence\n",
      "   Days 29-35: Face recognition + Alert system\n",
      "\n",
      "WEEK 6: Production system\n",
      "   Days 36-42: API + Dashboard + Deployment\n",
      "\n",
      "Final Deliverable:\n",
      "ğŸ¯ Complete, deployed security system\n",
      "ğŸ¯ Live demo with multiple features\n",
      "ğŸ¯ Professional documentation\n",
      "ğŸ¯ Portfolio showpiece\n",
      "ğŸ¯ Interview talking point\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ”’ AI SECURITY & SURVEILLANCE SYSTEM - PROJECT VISION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "PROJECT NAME: SecureVision AI\n",
    "Tagline: Intelligent surveillance that sees, tracks, and protects\n",
    "\n",
    "==================================================\n",
    "\n",
    "WHAT I'M GOING TO BUILD:\n",
    "\n",
    "A complete, production-ready AI security system that combines:\n",
    "âœ“ Real-time object detection (YOLO)\n",
    "âœ“ Multi-object tracking (DeepSORT)\n",
    "âœ“ Face recognition (FaceNet/DeepFace)\n",
    "âœ“ Automated alert system\n",
    "âœ“ Analytics dashboard\n",
    "âœ“ REST API for integration\n",
    "âœ“ Multi-camera support\n",
    "\n",
    "This is NOT just another detector!\n",
    "This is an INTEGRATED SYSTEM showing end-to-end ML engineering.\n",
    "\n",
    "==================================================\n",
    "\n",
    "REAL-WORLD USE CASES:\n",
    "\n",
    "ğŸ¢ OFFICE BUILDINGS\n",
    "   - Track employee movements\n",
    "   - Detect unauthorized access\n",
    "   - Monitor restricted areas\n",
    "   - Attendance tracking\n",
    "\n",
    "ğŸ­ MANUFACTURING FACILITIES\n",
    "   - Safety equipment compliance (PPE detection!)\n",
    "   - Worker count in dangerous zones\n",
    "   - Hazard area monitoring\n",
    "   - Incident detection\n",
    "\n",
    "ğŸª RETAIL STORES\n",
    "   - Customer traffic analysis\n",
    "   - Heat map generation\n",
    "   - Queue management\n",
    "   - Theft detection\n",
    "\n",
    "ğŸ« EDUCATIONAL INSTITUTIONS\n",
    "   - Campus security\n",
    "   - Attendance monitoring\n",
    "   - Visitor management\n",
    "   - Emergency response\n",
    "\n",
    "ğŸ  RESIDENTIAL SECURITY\n",
    "   - Recognize family vs strangers\n",
    "   - Package delivery alerts\n",
    "   - Unusual activity detection\n",
    "   - Remote monitoring\n",
    "\n",
    "==================================================\n",
    "\n",
    "WHY THIS PROJECT IS SPECIAL:\n",
    "\n",
    "1. REAL-TIME PROCESSING\n",
    "   Target: 30 FPS on standard hardware\n",
    "   Challenge: Multiple ML models in pipeline\n",
    "   \n",
    "2. MULTIPLE ML COMPONENTS\n",
    "   - Detection (YOLO)\n",
    "   - Tracking (DeepSORT)\n",
    "   - Recognition (FaceNet)\n",
    "   - Classification (PPE)\n",
    "   \n",
    "3. STATE MANAGEMENT\n",
    "   - Track objects across frames\n",
    "   - Maintain IDs through occlusions\n",
    "   - Handle multi-camera scenarios\n",
    "   \n",
    "4. PRODUCTION-READY\n",
    "   - REST API\n",
    "   - Database integration\n",
    "   - Deployment with Docker\n",
    "   - Monitoring and logging\n",
    "\n",
    "5. PORTFOLIO IMPACT\n",
    "   This demonstrates:\n",
    "   âœ“ System design skills\n",
    "   âœ“ Real-time ML\n",
    "   âœ“ Integration expertise\n",
    "   âœ“ Production engineering\n",
    "   âœ“ Full-stack ML development\n",
    "\n",
    "==================================================\n",
    "\n",
    "TECHNICAL COMPLEXITY:\n",
    "\n",
    "More complex than Week 3 (Medical Classifier):\n",
    "- Video processing vs single images\n",
    "- State management across frames\n",
    "- Multiple ML models integrated\n",
    "- Real-time performance requirements\n",
    "- Multi-component system\n",
    "\n",
    "But I'm READY! I already:\n",
    "âœ… Built YOLO detector (Week 2)\n",
    "âœ… Trained deep learning models (Week 3)\n",
    "âœ… Deployed web applications (Week 2 & 3)\n",
    "âœ… Handled complex pipelines\n",
    "\n",
    "This brings EVERYTHING together! ğŸ”¥\n",
    "\n",
    "==================================================\n",
    "\n",
    "PROJECT SCOPE - 3 WEEKS:\n",
    "\n",
    "WEEK 4: Build the foundation\n",
    "   Days 22-28: Detection + Tracking working at 30 FPS\n",
    "\n",
    "WEEK 5: Add intelligence\n",
    "   Days 29-35: Face recognition + Alert system\n",
    "\n",
    "WEEK 6: Production system\n",
    "   Days 36-42: API + Dashboard + Deployment\n",
    "\n",
    "Final Deliverable:\n",
    "ğŸ¯ Complete, deployed security system\n",
    "ğŸ¯ Live demo with multiple features\n",
    "ğŸ¯ Professional documentation\n",
    "ğŸ¯ Portfolio showpiece\n",
    "ğŸ¯ Interview talking point\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "892b083c-3658-4a3c-8120-d5f1a7a7c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ—ï¸ SYSTEM ARCHITECTURE - COMPLETE DESIGN\n",
      "================================================================================\n",
      "\n",
      "HIGH-LEVEL ARCHITECTURE:\n",
      "\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚                    VIDEO INPUT LAYER                         â”‚\n",
      "â”‚  ğŸ“¹ Camera 1  ğŸ“¹ Camera 2  ğŸ“¹ Camera 3  ğŸ’» Webcam  ğŸ“ Files â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                           â”‚\n",
      "                           â†“\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚              VIDEO PREPROCESSING MODULE                      â”‚\n",
      "â”‚  â€¢ Frame extraction (cv2.VideoCapture)                       â”‚\n",
      "â”‚  â€¢ Resize to standard resolution (640x480 or 1280x720)       â”‚\n",
      "â”‚  â€¢ Color space conversion (BGR â†’ RGB)                        â”‚\n",
      "â”‚  â€¢ Frame buffering and queue management                      â”‚\n",
      "â”‚  â€¢ FPS control and synchronization                           â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                           â”‚\n",
      "                           â†“\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚           DETECTION MODULE (YOLOv8) - WEEK 4                 â”‚\n",
      "â”‚  Input: RGB frames                                           â”‚\n",
      "â”‚  Output: Bounding boxes [x, y, w, h], confidence, class      â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Detects:                                                    â”‚\n",
      "â”‚  â€¢ People (person class)                                     â”‚\n",
      "â”‚  â€¢ Vehicles (car, truck, motorcycle)                         â”‚\n",
      "â”‚  â€¢ Objects (bag, phone, etc.)                                â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Performance: 30-50 FPS on GPU, 10-15 FPS on CPU             â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                           â”‚\n",
      "                           â†“\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚           TRACKING MODULE (DeepSORT) - WEEK 4                â”‚\n",
      "â”‚  Input: Detections from YOLO                                 â”‚\n",
      "â”‚  Output: Tracked objects with unique IDs                     â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Features:                                                   â”‚\n",
      "â”‚  â€¢ Kalman filter for motion prediction                       â”‚\n",
      "â”‚  â€¢ Deep appearance descriptor (ReID)                         â”‚\n",
      "â”‚  â€¢ Hungarian algorithm for data association                  â”‚\n",
      "â”‚  â€¢ Handle occlusions (max_age parameter)                     â”‚\n",
      "â”‚  â€¢ Re-identification when object reappears                   â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Tracking Info:                                              â”‚\n",
      "â”‚  â€¢ ID, bbox, class, track_history, age                       â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  People Counting:                                            â”‚\n",
      "â”‚  â€¢ Entry/exit line crossing detection                        â”‚\n",
      "â”‚  â€¢ Zone-based counting                                       â”‚\n",
      "â”‚  â€¢ Current count, peak count, total visitors                 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                           â”‚\n",
      "                           â†“\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚        FACE RECOGNITION MODULE - WEEK 5                      â”‚\n",
      "â”‚  Input: Tracked person bounding boxes                        â”‚\n",
      "â”‚  Output: Person identity + confidence                        â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Pipeline:                                                   â”‚\n",
      "â”‚  1. Face Detection (MTCNN or RetinaFace)                     â”‚\n",
      "â”‚  2. Face Alignment (5-point landmarks)                       â”‚\n",
      "â”‚  3. Face Quality Check (blur, pose, lighting)                â”‚\n",
      "â”‚  4. Face Embedding (FaceNet: 128D vector)                    â”‚\n",
      "â”‚  5. Database Matching (cosine similarity)                    â”‚\n",
      "â”‚  6. Classification (Known vs Unknown)                        â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Face Database:                                              â”‚\n",
      "â”‚  â€¢ Employee/authorized person faces                          â”‚\n",
      "â”‚  â€¢ Multiple images per person (different angles)             â”‚\n",
      "â”‚  â€¢ Embeddings pre-computed and indexed                       â”‚\n",
      "â”‚  â€¢ SQLite/PostgreSQL storage                                 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                           â”‚\n",
      "                           â†“\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚         SAFETY VIOLATION DETECTION - WEEK 5                  â”‚\n",
      "â”‚  (Integration of Week 2 PPE Detector!)                       â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Detects:                                                    â”‚\n",
      "â”‚  â€¢ Missing hardhat                                           â”‚\n",
      "â”‚  â€¢ Missing safety vest                                       â”‚\n",
      "â”‚  â€¢ Missing gloves (if required)                              â”‚\n",
      "â”‚  â€¢ Restricted area access                                    â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Alert Triggers:                                             â”‚\n",
      "â”‚  â€¢ Person in hazard zone without PPE                         â”‚\n",
      "â”‚  â€¢ Unknown person in restricted area                         â”‚\n",
      "â”‚  â€¢ Person count exceeds limit in zone                        â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                           â”‚\n",
      "                           â†“\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚            ALERT SYSTEM - WEEK 5                             â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Alert Types:                                                â”‚\n",
      "â”‚  ğŸš¨ Unknown Person Detected                                  â”‚\n",
      "â”‚  âš ï¸  Safety Violation (Missing PPE)                          â”‚\n",
      "â”‚  ğŸš« Restricted Area Breach                                   â”‚\n",
      "â”‚  ğŸ“Š Zone Capacity Exceeded                                   â”‚\n",
      "â”‚  ğŸƒ Unusual Movement Pattern                                â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Alert Channels:                                             â”‚\n",
      "â”‚  â€¢ Email (SMTP - Gmail, SendGrid)                            â”‚\n",
      "â”‚  â€¢ SMS (Twilio API - optional)                               â”‚\n",
      "â”‚  â€¢ Push Notifications (browser)                              â”‚\n",
      "â”‚  â€¢ In-app alerts (dashboard)                                 â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Alert Logic:                                                â”‚\n",
      "â”‚  â€¢ Rule engine (configurable conditions)                     â”‚\n",
      "â”‚  â€¢ Cooldown period (avoid spam)                              â”‚\n",
      "â”‚  â€¢ Priority levels (critical, warning, info)                 â”‚\n",
      "â”‚  â€¢ Alert history and logging                                 â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                           â”‚\n",
      "                           â†“\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚            DATABASE LAYER - WEEK 6                           â”‚\n",
      "â”‚  Technology: SQLite (development) or PostgreSQL (production) â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Tables:                                                     â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  detections:                                                 â”‚\n",
      "â”‚    - id, timestamp, camera_id, object_class, bbox,           â”‚\n",
      "â”‚      confidence, track_id                                    â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  tracks:                                                     â”‚\n",
      "â”‚    - track_id, first_seen, last_seen, total_frames,          â”‚\n",
      "â”‚      trajectory_data                                         â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  faces:                                                      â”‚\n",
      "â”‚    - face_id, person_name, embedding_vector, photo_path,     â”‚\n",
      "â”‚      added_date                                              â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  alerts:                                                     â”‚\n",
      "â”‚    - alert_id, timestamp, alert_type, severity, track_id,    â”‚\n",
      "â”‚      description, screenshot_path, resolved                  â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  analytics:                                                  â”‚\n",
      "â”‚    - date, camera_id, total_detections, unique_people,       â”‚\n",
      "â”‚      peak_count, avg_dwell_time                              â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                           â”‚\n",
      "                           â†“\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚           REST API (FastAPI) - WEEK 6                        â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Endpoints:                                                  â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  POST /api/v1/detect                                         â”‚\n",
      "â”‚    - Upload video/image for detection                        â”‚\n",
      "â”‚    - Returns: detections with bboxes                         â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  POST /api/v1/track                                          â”‚\n",
      "â”‚    - Start tracking on video stream                          â”‚\n",
      "â”‚    - Returns: tracked objects with IDs                       â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  POST /api/v1/recognize                                      â”‚\n",
      "â”‚    - Face recognition on image/video                         â”‚\n",
      "â”‚    - Returns: person identities                              â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  GET /api/v1/alerts                                          â”‚\n",
      "â”‚    - Get recent alerts (paginated)                           â”‚\n",
      "â”‚    - Filters: date, type, severity                           â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  GET /api/v1/analytics                                       â”‚\n",
      "â”‚    - Get system statistics                                   â”‚\n",
      "â”‚    - Returns: counts, heat maps, traffic data                â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  POST /api/v1/face/add                                       â”‚\n",
      "â”‚    - Add new person to face database                         â”‚\n",
      "â”‚    - Upload: name + multiple photos                          â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  GET /api/v1/status                                          â”‚\n",
      "â”‚    - System health check                                     â”‚\n",
      "â”‚    - Returns: cameras online, models loaded, etc.            â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Authentication: API key or JWT tokens                       â”‚\n",
      "â”‚  Rate Limiting: 100 requests/minute                          â”‚\n",
      "â”‚  Documentation: Auto-generated (Swagger UI)                  â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "                           â”‚\n",
      "                           â†“\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚         DASHBOARD (Streamlit/React) - WEEK 6                 â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  Features:                                                   â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  ğŸ“¹ Live Camera Feeds:                                       â”‚\n",
      "â”‚    - Multi-camera grid view                                  â”‚\n",
      "â”‚    - Detection/tracking overlays                             â”‚\n",
      "â”‚    - Real-time FPS counter                                   â”‚\n",
      "â”‚    - Zoom and pan controls                                   â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  ğŸ“Š Real-Time Stats:                                         â”‚\n",
      "â”‚    - Current people count per camera                         â”‚\n",
      "â”‚    - Total detections today                                  â”‚\n",
      "â”‚    - Active alerts                                           â”‚\n",
      "â”‚    - System status indicators                                â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  ğŸš¨ Alert Management:                                        â”‚\n",
      "â”‚    - Live alert feed                                         â”‚\n",
      "â”‚    - Alert details (screenshot, time, location)              â”‚\n",
      "â”‚    - Mark as resolved                                        â”‚\n",
      "â”‚    - Alert history viewer                                    â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  ğŸ‘¤ Face Database Management:                                â”‚\n",
      "â”‚    - View all registered faces                               â”‚\n",
      "â”‚    - Add new person (name + photos)                          â”‚\n",
      "â”‚    - Edit person info                                        â”‚\n",
      "â”‚    - Delete from database                                    â”‚\n",
      "â”‚    - Search functionality                                    â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  ğŸ“ˆ Analytics & Visualizations:                              â”‚\n",
      "â”‚    - Heat maps (where people spend time)                     â”‚\n",
      "â”‚    - Traffic flow diagrams                                   â”‚\n",
      "â”‚    - Hourly/daily/weekly charts                              â”‚\n",
      "â”‚    - Peak hours analysis                                     â”‚\n",
      "â”‚    - Zone-based analytics                                    â”‚\n",
      "â”‚    - Export reports (PDF, CSV, Excel)                        â”‚\n",
      "â”‚                                                              â”‚\n",
      "â”‚  âš™ï¸ Configuration:                                           â”‚\n",
      "â”‚    - Camera management (add/remove/configure)                â”‚\n",
      "â”‚    - Alert rules configuration                               â”‚\n",
      "â”‚    - Detection sensitivity settings                          â”‚\n",
      "â”‚    - Zone definitions (restricted areas)                     â”‚\n",
      "â”‚    - Notification preferences                                â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
      "\n",
      "==================================================\n",
      "\n",
      "DATA FLOW SUMMARY:\n",
      "\n",
      "Video â†’ Preprocess â†’ Detect (YOLO) â†’ Track (DeepSORT) â†’ \n",
      "Recognize (FaceNet) â†’ Check Rules â†’ Alert â†’ Store â†’ \n",
      "Display (Dashboard) + Serve (API)\n",
      "\n",
      "==================================================\n",
      "\n",
      "PERFORMANCE TARGETS:\n",
      "\n",
      "Detection: 30-50 FPS (GPU), 10-15 FPS (CPU)\n",
      "Tracking: Maintain IDs through 30+ frame occlusions\n",
      "Recognition: <100ms per face\n",
      "Alert Latency: <1 second from detection to notification\n",
      "API Response: <200ms for queries\n",
      "Dashboard: Real-time updates (1-2 second lag max)\n",
      "\n",
      "==================================================\n",
      "\n",
      "TECHNOLOGY STACK:\n",
      "\n",
      "Core ML:\n",
      "- YOLOv8 (Ultralytics) - Object detection\n",
      "- DeepSORT - Multi-object tracking\n",
      "- FaceNet/DeepFace - Face recognition\n",
      "\n",
      "Backend:\n",
      "- Python 3.10+\n",
      "- FastAPI - REST API\n",
      "- SQLite/PostgreSQL - Database\n",
      "- OpenCV - Video processing\n",
      "\n",
      "Frontend:\n",
      "- Streamlit (Option 1)\n",
      "- React + TypeScript (Option 2 - more professional)\n",
      "\n",
      "Deployment:\n",
      "- Docker + Docker Compose\n",
      "- Nginx (reverse proxy)\n",
      "- Gunicorn (WSGI server)\n",
      "\n",
      "Optional:\n",
      "- Redis (caching)\n",
      "- Celery (background tasks)\n",
      "- AWS S3 (video storage)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ—ï¸ SYSTEM ARCHITECTURE - COMPLETE DESIGN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "HIGH-LEVEL ARCHITECTURE:\n",
    "\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    VIDEO INPUT LAYER                         â”‚\n",
    "â”‚  ğŸ“¹ Camera 1  ğŸ“¹ Camera 2  ğŸ“¹ Camera 3  ğŸ’» Webcam  ğŸ“ Files â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚              VIDEO PREPROCESSING MODULE                      â”‚\n",
    "â”‚  â€¢ Frame extraction (cv2.VideoCapture)                       â”‚\n",
    "â”‚  â€¢ Resize to standard resolution (640x480 or 1280x720)       â”‚\n",
    "â”‚  â€¢ Color space conversion (BGR â†’ RGB)                        â”‚\n",
    "â”‚  â€¢ Frame buffering and queue management                      â”‚\n",
    "â”‚  â€¢ FPS control and synchronization                           â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           DETECTION MODULE (YOLOv8) - WEEK 4                 â”‚\n",
    "â”‚  Input: RGB frames                                           â”‚\n",
    "â”‚  Output: Bounding boxes [x, y, w, h], confidence, class      â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Detects:                                                    â”‚\n",
    "â”‚  â€¢ People (person class)                                     â”‚\n",
    "â”‚  â€¢ Vehicles (car, truck, motorcycle)                         â”‚\n",
    "â”‚  â€¢ Objects (bag, phone, etc.)                                â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Performance: 30-50 FPS on GPU, 10-15 FPS on CPU             â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           TRACKING MODULE (DeepSORT) - WEEK 4                â”‚\n",
    "â”‚  Input: Detections from YOLO                                 â”‚\n",
    "â”‚  Output: Tracked objects with unique IDs                     â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Features:                                                   â”‚\n",
    "â”‚  â€¢ Kalman filter for motion prediction                       â”‚\n",
    "â”‚  â€¢ Deep appearance descriptor (ReID)                         â”‚\n",
    "â”‚  â€¢ Hungarian algorithm for data association                  â”‚\n",
    "â”‚  â€¢ Handle occlusions (max_age parameter)                     â”‚\n",
    "â”‚  â€¢ Re-identification when object reappears                   â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Tracking Info:                                              â”‚\n",
    "â”‚  â€¢ ID, bbox, class, track_history, age                       â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  People Counting:                                            â”‚\n",
    "â”‚  â€¢ Entry/exit line crossing detection                        â”‚\n",
    "â”‚  â€¢ Zone-based counting                                       â”‚\n",
    "â”‚  â€¢ Current count, peak count, total visitors                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚        FACE RECOGNITION MODULE - WEEK 5                      â”‚\n",
    "â”‚  Input: Tracked person bounding boxes                        â”‚\n",
    "â”‚  Output: Person identity + confidence                        â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Pipeline:                                                   â”‚\n",
    "â”‚  1. Face Detection (MTCNN or RetinaFace)                     â”‚\n",
    "â”‚  2. Face Alignment (5-point landmarks)                       â”‚\n",
    "â”‚  3. Face Quality Check (blur, pose, lighting)                â”‚\n",
    "â”‚  4. Face Embedding (FaceNet: 128D vector)                    â”‚\n",
    "â”‚  5. Database Matching (cosine similarity)                    â”‚\n",
    "â”‚  6. Classification (Known vs Unknown)                        â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Face Database:                                              â”‚\n",
    "â”‚  â€¢ Employee/authorized person faces                          â”‚\n",
    "â”‚  â€¢ Multiple images per person (different angles)             â”‚\n",
    "â”‚  â€¢ Embeddings pre-computed and indexed                       â”‚\n",
    "â”‚  â€¢ SQLite/PostgreSQL storage                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         SAFETY VIOLATION DETECTION - WEEK 5                  â”‚\n",
    "â”‚  (Integration of Week 2 PPE Detector!)                       â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Detects:                                                    â”‚\n",
    "â”‚  â€¢ Missing hardhat                                           â”‚\n",
    "â”‚  â€¢ Missing safety vest                                       â”‚\n",
    "â”‚  â€¢ Missing gloves (if required)                              â”‚\n",
    "â”‚  â€¢ Restricted area access                                    â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Alert Triggers:                                             â”‚\n",
    "â”‚  â€¢ Person in hazard zone without PPE                         â”‚\n",
    "â”‚  â€¢ Unknown person in restricted area                         â”‚\n",
    "â”‚  â€¢ Person count exceeds limit in zone                        â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚            ALERT SYSTEM - WEEK 5                             â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Alert Types:                                                â”‚\n",
    "â”‚  ğŸš¨ Unknown Person Detected                                  â”‚\n",
    "â”‚  âš ï¸  Safety Violation (Missing PPE)                          â”‚\n",
    "â”‚  ğŸš« Restricted Area Breach                                   â”‚\n",
    "â”‚  ğŸ“Š Zone Capacity Exceeded                                   â”‚\n",
    "â”‚  ğŸƒ Unusual Movement Pattern                                â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Alert Channels:                                             â”‚\n",
    "â”‚  â€¢ Email (SMTP - Gmail, SendGrid)                            â”‚\n",
    "â”‚  â€¢ SMS (Twilio API - optional)                               â”‚\n",
    "â”‚  â€¢ Push Notifications (browser)                              â”‚\n",
    "â”‚  â€¢ In-app alerts (dashboard)                                 â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Alert Logic:                                                â”‚\n",
    "â”‚  â€¢ Rule engine (configurable conditions)                     â”‚\n",
    "â”‚  â€¢ Cooldown period (avoid spam)                              â”‚\n",
    "â”‚  â€¢ Priority levels (critical, warning, info)                 â”‚\n",
    "â”‚  â€¢ Alert history and logging                                 â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚            DATABASE LAYER - WEEK 6                           â”‚\n",
    "â”‚  Technology: SQLite (development) or PostgreSQL (production) â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Tables:                                                     â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  detections:                                                 â”‚\n",
    "â”‚    - id, timestamp, camera_id, object_class, bbox,           â”‚\n",
    "â”‚      confidence, track_id                                    â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  tracks:                                                     â”‚\n",
    "â”‚    - track_id, first_seen, last_seen, total_frames,          â”‚\n",
    "â”‚      trajectory_data                                         â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  faces:                                                      â”‚\n",
    "â”‚    - face_id, person_name, embedding_vector, photo_path,     â”‚\n",
    "â”‚      added_date                                              â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  alerts:                                                     â”‚\n",
    "â”‚    - alert_id, timestamp, alert_type, severity, track_id,    â”‚\n",
    "â”‚      description, screenshot_path, resolved                  â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  analytics:                                                  â”‚\n",
    "â”‚    - date, camera_id, total_detections, unique_people,       â”‚\n",
    "â”‚      peak_count, avg_dwell_time                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           REST API (FastAPI) - WEEK 6                        â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Endpoints:                                                  â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  POST /api/v1/detect                                         â”‚\n",
    "â”‚    - Upload video/image for detection                        â”‚\n",
    "â”‚    - Returns: detections with bboxes                         â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  POST /api/v1/track                                          â”‚\n",
    "â”‚    - Start tracking on video stream                          â”‚\n",
    "â”‚    - Returns: tracked objects with IDs                       â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  POST /api/v1/recognize                                      â”‚\n",
    "â”‚    - Face recognition on image/video                         â”‚\n",
    "â”‚    - Returns: person identities                              â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  GET /api/v1/alerts                                          â”‚\n",
    "â”‚    - Get recent alerts (paginated)                           â”‚\n",
    "â”‚    - Filters: date, type, severity                           â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  GET /api/v1/analytics                                       â”‚\n",
    "â”‚    - Get system statistics                                   â”‚\n",
    "â”‚    - Returns: counts, heat maps, traffic data                â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  POST /api/v1/face/add                                       â”‚\n",
    "â”‚    - Add new person to face database                         â”‚\n",
    "â”‚    - Upload: name + multiple photos                          â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  GET /api/v1/status                                          â”‚\n",
    "â”‚    - System health check                                     â”‚\n",
    "â”‚    - Returns: cameras online, models loaded, etc.            â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Authentication: API key or JWT tokens                       â”‚\n",
    "â”‚  Rate Limiting: 100 requests/minute                          â”‚\n",
    "â”‚  Documentation: Auto-generated (Swagger UI)                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â”‚\n",
    "                           â†“\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚         DASHBOARD (Streamlit/React) - WEEK 6                 â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  Features:                                                   â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  ğŸ“¹ Live Camera Feeds:                                       â”‚\n",
    "â”‚    - Multi-camera grid view                                  â”‚\n",
    "â”‚    - Detection/tracking overlays                             â”‚\n",
    "â”‚    - Real-time FPS counter                                   â”‚\n",
    "â”‚    - Zoom and pan controls                                   â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  ğŸ“Š Real-Time Stats:                                         â”‚\n",
    "â”‚    - Current people count per camera                         â”‚\n",
    "â”‚    - Total detections today                                  â”‚\n",
    "â”‚    - Active alerts                                           â”‚\n",
    "â”‚    - System status indicators                                â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  ğŸš¨ Alert Management:                                        â”‚\n",
    "â”‚    - Live alert feed                                         â”‚\n",
    "â”‚    - Alert details (screenshot, time, location)              â”‚\n",
    "â”‚    - Mark as resolved                                        â”‚\n",
    "â”‚    - Alert history viewer                                    â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  ğŸ‘¤ Face Database Management:                                â”‚\n",
    "â”‚    - View all registered faces                               â”‚\n",
    "â”‚    - Add new person (name + photos)                          â”‚\n",
    "â”‚    - Edit person info                                        â”‚\n",
    "â”‚    - Delete from database                                    â”‚\n",
    "â”‚    - Search functionality                                    â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  ğŸ“ˆ Analytics & Visualizations:                              â”‚\n",
    "â”‚    - Heat maps (where people spend time)                     â”‚\n",
    "â”‚    - Traffic flow diagrams                                   â”‚\n",
    "â”‚    - Hourly/daily/weekly charts                              â”‚\n",
    "â”‚    - Peak hours analysis                                     â”‚\n",
    "â”‚    - Zone-based analytics                                    â”‚\n",
    "â”‚    - Export reports (PDF, CSV, Excel)                        â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚  âš™ï¸ Configuration:                                           â”‚\n",
    "â”‚    - Camera management (add/remove/configure)                â”‚\n",
    "â”‚    - Alert rules configuration                               â”‚\n",
    "â”‚    - Detection sensitivity settings                          â”‚\n",
    "â”‚    - Zone definitions (restricted areas)                     â”‚\n",
    "â”‚    - Notification preferences                                â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "\n",
    "==================================================\n",
    "\n",
    "DATA FLOW SUMMARY:\n",
    "\n",
    "Video â†’ Preprocess â†’ Detect (YOLO) â†’ Track (DeepSORT) â†’ \n",
    "Recognize (FaceNet) â†’ Check Rules â†’ Alert â†’ Store â†’ \n",
    "Display (Dashboard) + Serve (API)\n",
    "\n",
    "==================================================\n",
    "\n",
    "PERFORMANCE TARGETS:\n",
    "\n",
    "Detection: 30-50 FPS (GPU), 10-15 FPS (CPU)\n",
    "Tracking: Maintain IDs through 30+ frame occlusions\n",
    "Recognition: <100ms per face\n",
    "Alert Latency: <1 second from detection to notification\n",
    "API Response: <200ms for queries\n",
    "Dashboard: Real-time updates (1-2 second lag max)\n",
    "\n",
    "==================================================\n",
    "\n",
    "TECHNOLOGY STACK:\n",
    "\n",
    "Core ML:\n",
    "- YOLOv8 (Ultralytics) - Object detection\n",
    "- DeepSORT - Multi-object tracking\n",
    "- FaceNet/DeepFace - Face recognition\n",
    "\n",
    "Backend:\n",
    "- Python 3.10+\n",
    "- FastAPI - REST API\n",
    "- SQLite/PostgreSQL - Database\n",
    "- OpenCV - Video processing\n",
    "\n",
    "Frontend:\n",
    "- Streamlit (Option 1)\n",
    "- React + TypeScript (Option 2 - more professional)\n",
    "\n",
    "Deployment:\n",
    "- Docker + Docker Compose\n",
    "- Nginx (reverse proxy)\n",
    "- Gunicorn (WSGI server)\n",
    "\n",
    "Optional:\n",
    "- Redis (caching)\n",
    "- Celery (background tasks)\n",
    "- AWS S3 (video storage)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d827af7-736e-4c27-821b-3b5c63d18680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“… WEEK 4: DETECTION & TRACKING - DETAILED PLAN\n",
      "================================================================================\n",
      "\n",
      "GOAL: Build detection and tracking foundation (30 FPS)\n",
      "\n",
      "==================================================\n",
      "\n",
      "DAY 22 (MONDAY - TODAY): PROJECT PLANNING\n",
      "âœ… Design system architecture\n",
      "âœ… Review YOLOv8 from Week 2\n",
      "âœ… Test YOLO on videos\n",
      "âœ… Plan tracking integration\n",
      "âœ… Setup project structure\n",
      "\n",
      "Deliverable: Architecture documented, YOLO working on videos\n",
      "\n",
      "==================================================\n",
      "\n",
      "DAY 23 (TUESDAY): MULTI-OBJECT TRACKING\n",
      "\n",
      "Morning:\n",
      "- DeepSORT theory study (2-3 hours)\n",
      "  - Kalman filter for motion prediction\n",
      "  - Appearance descriptor (ReID network)\n",
      "  - Hungarian algorithm for matching\n",
      "  - Track lifecycle management\n",
      "\n",
      "Afternoon:\n",
      "- Install DeepSORT\n",
      "- Integrate YOLO + DeepSORT\n",
      "- First tracking test on video\n",
      "- Visualize tracks with IDs\n",
      "\n",
      "Evening:\n",
      "- Debug tracking issues\n",
      "- Test on different videos\n",
      "- Document integration code\n",
      "\n",
      "Deliverable: YOLO + DeepSORT working, objects tracked with IDs\n",
      "\n",
      "==================================================\n",
      "\n",
      "DAY 24 (WEDNESDAY): TRACKING OPTIMIZATION\n",
      "\n",
      "Tasks:\n",
      "- Handle occlusions (max_age parameter tuning)\n",
      "- Re-identification when object reappears\n",
      "- Track across camera views (if multi-camera)\n",
      "- Implement people counting:\n",
      "  - Define entry/exit lines\n",
      "  - Count crossings\n",
      "  - Maintain total count\n",
      "- Optimize tracking parameters:\n",
      "  - IOU threshold\n",
      "  - Max age\n",
      "  - Min hits\n",
      "  - NMS threshold\n",
      "\n",
      "Testing:\n",
      "- Crowded scenes\n",
      "- Sparse scenes\n",
      "- Occlusions\n",
      "- Fast movement\n",
      "\n",
      "Deliverable: Robust tracking with counting\n",
      "\n",
      "==================================================\n",
      "\n",
      "DAY 25 (THURSDAY): VIDEO PROCESSING PIPELINE\n",
      "\n",
      "Build production-ready pipeline:\n",
      "\n",
      "- Multi-threaded video reading\n",
      "- Frame queue management\n",
      "- FPS control and synchronization\n",
      "- Memory management (prevent leaks)\n",
      "- Support multiple input sources:\n",
      "  - Video files (MP4, AVI)\n",
      "  - Webcam\n",
      "  - RTSP streams (IP cameras)\n",
      "  - Multiple cameras simultaneously\n",
      "\n",
      "Performance Optimization:\n",
      "- Resize frames before detection\n",
      "- Batch processing (if possible)\n",
      "- Skip frame strategy (if needed)\n",
      "- GPU utilization optimization\n",
      "\n",
      "Deliverable: 30 FPS processing pipeline\n",
      "\n",
      "==================================================\n",
      "\n",
      "DAY 26 (FRIDAY): TESTING & PERFORMANCE\n",
      "\n",
      "Comprehensive Testing:\n",
      "- Test various scenarios:\n",
      "  - Indoor/outdoor\n",
      "  - Day/night (lighting)\n",
      "  - Crowded/sparse\n",
      "  - Different resolutions\n",
      "- Performance profiling:\n",
      "  - Find bottlenecks\n",
      "  - Optimize slow parts\n",
      "  - Memory usage analysis\n",
      "- Accuracy metrics:\n",
      "  - Track accuracy (MOTA)\n",
      "  - ID switches\n",
      "  - False positives/negatives\n",
      "\n",
      "Bug Fixing:\n",
      "- Fix any tracking failures\n",
      "- Handle edge cases\n",
      "- Error handling\n",
      "\n",
      "Deliverable: Tested, optimized system\n",
      "\n",
      "==================================================\n",
      "\n",
      "DAY 27 (SATURDAY): CODE CLEANUP & MODULARIZATION\n",
      "\n",
      "Refactoring:\n",
      "- Create modular architecture:\n",
      "  - detector.py (YOLO wrapper)\n",
      "  - tracker.py (DeepSORT wrapper)\n",
      "  - video_processor.py (video I/O)\n",
      "  - counter.py (people counting)\n",
      "  - visualizer.py (drawing functions)\n",
      "  - utils.py (helper functions)\n",
      "\n",
      "- Clean code:\n",
      "  - Add docstrings\n",
      "  - Type hints\n",
      "  - Remove commented code\n",
      "  - Consistent naming\n",
      "\n",
      "- Configuration:\n",
      "  - Config file (YAML/JSON)\n",
      "  - All parameters configurable\n",
      "  - No hardcoded values\n",
      "\n",
      "Documentation:\n",
      "- Code comments\n",
      "- README with setup instructions\n",
      "- Usage examples\n",
      "\n",
      "Deliverable: Clean, modular codebase\n",
      "\n",
      "==================================================\n",
      "\n",
      "DAY 28 (SUNDAY): WEEK 4 REVIEW & PREPARATION\n",
      "\n",
      "Review:\n",
      "- Test entire system end-to-end\n",
      "- Create demo video (tracking in action)\n",
      "- Measure performance (FPS, accuracy)\n",
      "- Identify improvements for next week\n",
      "\n",
      "Prepare for Week 5:\n",
      "- Research face recognition libraries\n",
      "- Download face datasets\n",
      "- Plan face recognition integration\n",
      "- Design face database schema\n",
      "\n",
      "Documentation:\n",
      "- Week 4 summary notebook\n",
      "- What worked / What didn't\n",
      "- Lessons learned\n",
      "- Next steps\n",
      "\n",
      "Deliverable: Week 4 complete, ready for Week 5\n",
      "\n",
      "==================================================\n",
      "\n",
      "WEEK 4 FINAL DELIVERABLE:\n",
      "\n",
      "âœ… Detection + Tracking system working at 30 FPS\n",
      "âœ… People counting functional\n",
      "âœ… Handles multiple videos/cameras\n",
      "âœ… Clean, modular code\n",
      "âœ… Documented and tested\n",
      "âœ… Ready for face recognition integration\n",
      "\n",
      "Files by end of Week 4:\n",
      "- day22_project_planning.ipynb\n",
      "- day23_deepsort_integration.ipynb\n",
      "- day24_tracking_optimization.ipynb\n",
      "- day25_video_pipeline.ipynb\n",
      "- day26_testing_performance.ipynb\n",
      "- day27_code_cleanup.ipynb\n",
      "- day28_week4_review.ipynb\n",
      "- detector.py\n",
      "- tracker.py\n",
      "- video_processor.py\n",
      "- counter.py\n",
      "- visualizer.py\n",
      "- utils.py\n",
      "- config.yaml\n",
      "- requirements.txt\n",
      "- README.md\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“… WEEK 4: DETECTION & TRACKING - DETAILED PLAN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "GOAL: Build detection and tracking foundation (30 FPS)\n",
    "\n",
    "==================================================\n",
    "\n",
    "DAY 22 (MONDAY - TODAY): PROJECT PLANNING\n",
    "âœ… Design system architecture\n",
    "âœ… Review YOLOv8 from Week 2\n",
    "âœ… Test YOLO on videos\n",
    "âœ… Plan tracking integration\n",
    "âœ… Setup project structure\n",
    "\n",
    "Deliverable: Architecture documented, YOLO working on videos\n",
    "\n",
    "==================================================\n",
    "\n",
    "DAY 23 (TUESDAY): MULTI-OBJECT TRACKING\n",
    "\n",
    "Morning:\n",
    "- DeepSORT theory study (2-3 hours)\n",
    "  - Kalman filter for motion prediction\n",
    "  - Appearance descriptor (ReID network)\n",
    "  - Hungarian algorithm for matching\n",
    "  - Track lifecycle management\n",
    "\n",
    "Afternoon:\n",
    "- Install DeepSORT\n",
    "- Integrate YOLO + DeepSORT\n",
    "- First tracking test on video\n",
    "- Visualize tracks with IDs\n",
    "\n",
    "Evening:\n",
    "- Debug tracking issues\n",
    "- Test on different videos\n",
    "- Document integration code\n",
    "\n",
    "Deliverable: YOLO + DeepSORT working, objects tracked with IDs\n",
    "\n",
    "==================================================\n",
    "\n",
    "DAY 24 (WEDNESDAY): TRACKING OPTIMIZATION\n",
    "\n",
    "Tasks:\n",
    "- Handle occlusions (max_age parameter tuning)\n",
    "- Re-identification when object reappears\n",
    "- Track across camera views (if multi-camera)\n",
    "- Implement people counting:\n",
    "  - Define entry/exit lines\n",
    "  - Count crossings\n",
    "  - Maintain total count\n",
    "- Optimize tracking parameters:\n",
    "  - IOU threshold\n",
    "  - Max age\n",
    "  - Min hits\n",
    "  - NMS threshold\n",
    "\n",
    "Testing:\n",
    "- Crowded scenes\n",
    "- Sparse scenes\n",
    "- Occlusions\n",
    "- Fast movement\n",
    "\n",
    "Deliverable: Robust tracking with counting\n",
    "\n",
    "==================================================\n",
    "\n",
    "DAY 25 (THURSDAY): VIDEO PROCESSING PIPELINE\n",
    "\n",
    "Build production-ready pipeline:\n",
    "\n",
    "- Multi-threaded video reading\n",
    "- Frame queue management\n",
    "- FPS control and synchronization\n",
    "- Memory management (prevent leaks)\n",
    "- Support multiple input sources:\n",
    "  - Video files (MP4, AVI)\n",
    "  - Webcam\n",
    "  - RTSP streams (IP cameras)\n",
    "  - Multiple cameras simultaneously\n",
    "\n",
    "Performance Optimization:\n",
    "- Resize frames before detection\n",
    "- Batch processing (if possible)\n",
    "- Skip frame strategy (if needed)\n",
    "- GPU utilization optimization\n",
    "\n",
    "Deliverable: 30 FPS processing pipeline\n",
    "\n",
    "==================================================\n",
    "\n",
    "DAY 26 (FRIDAY): TESTING & PERFORMANCE\n",
    "\n",
    "Comprehensive Testing:\n",
    "- Test various scenarios:\n",
    "  - Indoor/outdoor\n",
    "  - Day/night (lighting)\n",
    "  - Crowded/sparse\n",
    "  - Different resolutions\n",
    "- Performance profiling:\n",
    "  - Find bottlenecks\n",
    "  - Optimize slow parts\n",
    "  - Memory usage analysis\n",
    "- Accuracy metrics:\n",
    "  - Track accuracy (MOTA)\n",
    "  - ID switches\n",
    "  - False positives/negatives\n",
    "\n",
    "Bug Fixing:\n",
    "- Fix any tracking failures\n",
    "- Handle edge cases\n",
    "- Error handling\n",
    "\n",
    "Deliverable: Tested, optimized system\n",
    "\n",
    "==================================================\n",
    "\n",
    "DAY 27 (SATURDAY): CODE CLEANUP & MODULARIZATION\n",
    "\n",
    "Refactoring:\n",
    "- Create modular architecture:\n",
    "  - detector.py (YOLO wrapper)\n",
    "  - tracker.py (DeepSORT wrapper)\n",
    "  - video_processor.py (video I/O)\n",
    "  - counter.py (people counting)\n",
    "  - visualizer.py (drawing functions)\n",
    "  - utils.py (helper functions)\n",
    "\n",
    "- Clean code:\n",
    "  - Add docstrings\n",
    "  - Type hints\n",
    "  - Remove commented code\n",
    "  - Consistent naming\n",
    "\n",
    "- Configuration:\n",
    "  - Config file (YAML/JSON)\n",
    "  - All parameters configurable\n",
    "  - No hardcoded values\n",
    "\n",
    "Documentation:\n",
    "- Code comments\n",
    "- README with setup instructions\n",
    "- Usage examples\n",
    "\n",
    "Deliverable: Clean, modular codebase\n",
    "\n",
    "==================================================\n",
    "\n",
    "DAY 28 (SUNDAY): WEEK 4 REVIEW & PREPARATION\n",
    "\n",
    "Review:\n",
    "- Test entire system end-to-end\n",
    "- Create demo video (tracking in action)\n",
    "- Measure performance (FPS, accuracy)\n",
    "- Identify improvements for next week\n",
    "\n",
    "Prepare for Week 5:\n",
    "- Research face recognition libraries\n",
    "- Download face datasets\n",
    "- Plan face recognition integration\n",
    "- Design face database schema\n",
    "\n",
    "Documentation:\n",
    "- Week 4 summary notebook\n",
    "- What worked / What didn't\n",
    "- Lessons learned\n",
    "- Next steps\n",
    "\n",
    "Deliverable: Week 4 complete, ready for Week 5\n",
    "\n",
    "==================================================\n",
    "\n",
    "WEEK 4 FINAL DELIVERABLE:\n",
    "\n",
    "âœ… Detection + Tracking system working at 30 FPS\n",
    "âœ… People counting functional\n",
    "âœ… Handles multiple videos/cameras\n",
    "âœ… Clean, modular code\n",
    "âœ… Documented and tested\n",
    "âœ… Ready for face recognition integration\n",
    "\n",
    "Files by end of Week 4:\n",
    "- day22_project_planning.ipynb\n",
    "- day23_deepsort_integration.ipynb\n",
    "- day24_tracking_optimization.ipynb\n",
    "- day25_video_pipeline.ipynb\n",
    "- day26_testing_performance.ipynb\n",
    "- day27_code_cleanup.ipynb\n",
    "- day28_week4_review.ipynb\n",
    "- detector.py\n",
    "- tracker.py\n",
    "- video_processor.py\n",
    "- counter.py\n",
    "- visualizer.py\n",
    "- utils.py\n",
    "- config.yaml\n",
    "- requirements.txt\n",
    "- README.md\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b1ee0c-79fb-4b5a-858f-bfbd6301fe99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” YOLO REVIEW\n",
      "================================================================================\n",
      "\n",
      "In Week 2, I built a Safety Equipment Detector with YOLOv8.\n",
      "I'll review what I learned and how it applies here!\n",
      "\n",
      "==================================================\n",
      "\n",
      "YOLO FUNDAMENTALS (What I learned):\n",
      "\n",
      "1. YOLO ARCHITECTURE\n",
      "   â€¢ Single-stage detector (fast!)\n",
      "   â€¢ Divides image into grid\n",
      "   â€¢ Each cell predicts bounding boxes\n",
      "   â€¢ Non-Maximum Suppression (NMS) removes duplicates\n",
      "\n",
      "2. TRAINING PROCESS\n",
      "   â€¢ Data annotation (Roboflow)\n",
      "   â€¢ Custom dataset preparation\n",
      "   â€¢ Model training with Ultralytics\n",
      "   â€¢ Hyperparameter tuning\n",
      "   â€¢ Achieved 75.1% mAP\n",
      "\n",
      "3. INFERENCE\n",
      "   â€¢ model.predict() for detection\n",
      "   â€¢ Confidence thresholds\n",
      "   â€¢ Class filtering\n",
      "   â€¢ Real-time processing\n",
      "\n",
      "==================================================\n",
      "\n",
      "MY WEEK 2 PROJECT:\n",
      "\n",
      "âœ… Safety Equipment Detector\n",
      "   - Detected: Hardhat, Safety Vest, Person\n",
      "   - 75.1% mAP performance\n",
      "   - Deployed on Streamlit\n",
      "   - Real-time detection\n",
      "\n",
      "Key Skills Gained:\n",
      "- YOLOv8 API (Ultralytics)\n",
      "- Data annotation workflow\n",
      "- Model training and evaluation\n",
      "- Web deployment\n",
      "- Real-time inference\n",
      "\n",
      "==================================================\n",
      "\n",
      "WHAT'S DIFFERENT FOR SECURITY SYSTEM:\n",
      "\n",
      "âœ… Safety Equipment Detector\n",
      "   - Detected: Hardhat, Safety Vest, Person\n",
      "   - 75.1% mAP performance\n",
      "   - Deployed on Streamlit\n",
      "   - Real-time detection\n",
      "\n",
      "Key Skills Gained:\n",
      "- YOLOv8 API (Ultralytics)\n",
      "- Data annotation workflow\n",
      "- Model training and evaluation\n",
      "- Web deployment\n",
      "- Real-time inference\n",
      "\n",
      "==================================================\n",
      "\n",
      "WHAT'S DIFFERENT FOR SECURITY SYSTEM:\n",
      "\n",
      "Week 2 (PPE Detector):\n",
      "- Single image/frame detection\n",
      "- Static objects (hardhats, vests)\n",
      "- No tracking across frames\n",
      "- Classification task\n",
      "\n",
      "Week 4-6 (Security System):\n",
      "- Video stream processing\n",
      "- Tracking people across frames\n",
      "- Maintaining object IDs\n",
      "- State management\n",
      "- Multi-component system\n",
      "\n",
      "==================================================\n",
      "\n",
      "YOLO FOR SECURITY SYSTEM:\n",
      "\n",
      "We'll use YOLOv8 for:\n",
      "1. Detecting PEOPLE in video frames\n",
      "2. Getting bounding boxes [x, y, w, h]\n",
      "3. Feeding detections to tracker\n",
      "4. 30 FPS real-time processing\n",
      "\n",
      "Later (Week 5, Day 34):\n",
      "I'll INTEGRATE my Week 2 PPE detector!\n",
      "- Run on tracked people\n",
      "- Check for safety violations\n",
      "- Multi-condition alerts\n",
      "\n",
      "==================================================\n",
      "\n",
      "QUICK YOLO REFRESHER:\n",
      "\n",
      "from ultralytics import YOLO\n",
      "\n",
      "# Load model\n",
      "model = YOLO('yolov8n.pt')  # nano (fastest)\n",
      "# or yolov8s.pt (small), yolov8m.pt (medium)\n",
      "\n",
      "# Detect on image\n",
      "results = model.predict(image, conf=0.5)\n",
      "\n",
      "# Get detections\n",
      "for result in results:\n",
      "    boxes = result.boxes  # Bounding boxes\n",
      "    for box in boxes:\n",
      "        x1, y1, x2, y2 = box.xyxy[0]  # Coordinates\n",
      "        conf = box.conf[0]            # Confidence\n",
      "        cls = box.cls[0]              # Class ID\n",
      "\n",
      "# Detect on video\n",
      "results = model.predict(source='video.mp4', stream=True)\n",
      "for result in results:\n",
      "    # Process each frame\n",
      "    pass\n",
      "\n",
      "==================================================\n",
      "\n",
      "YOLO MODELS (Speed vs Accuracy):\n",
      "\n",
      "YOLOv8n (Nano):    80 FPS, 37.3 mAP  â† Best for real-time\n",
      "YOLOv8s (Small):   50 FPS, 44.9 mAP\n",
      "YOLOv8m (Medium):  30 FPS, 50.2 mAP  â† Good balance\n",
      "YOLOv8l (Large):   20 FPS, 52.9 mAP\n",
      "YOLOv8x (XLarge):  15 FPS, 53.9 mAP\n",
      "\n",
      "For 30 FPS target: Use YOLOv8n or YOLOv8s\n",
      "\n",
      "==================================================\n",
      "\n",
      "WHAT I'LL DO TODAY:\n",
      "\n",
      "âœ… Install YOLOv8 (ultralytics)\n",
      "âœ… Test YOLO on video file\n",
      "âœ… Detect people only (class=0)\n",
      "âœ… Visualize detections\n",
      "âœ… Measure FPS performance\n",
      "âœ… Prepare for tracking integration (Day 23)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ” YOLO REVIEW\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "In Week 2, I built a Safety Equipment Detector with YOLOv8.\n",
    "I'll review what I learned and how it applies here!\n",
    "\n",
    "==================================================\n",
    "\n",
    "YOLO FUNDAMENTALS (What I learned):\n",
    "\n",
    "1. YOLO ARCHITECTURE\n",
    "   â€¢ Single-stage detector (fast!)\n",
    "   â€¢ Divides image into grid\n",
    "   â€¢ Each cell predicts bounding boxes\n",
    "   â€¢ Non-Maximum Suppression (NMS) removes duplicates\n",
    "   \n",
    "2. TRAINING PROCESS\n",
    "   â€¢ Data annotation (Roboflow)\n",
    "   â€¢ Custom dataset preparation\n",
    "   â€¢ Model training with Ultralytics\n",
    "   â€¢ Hyperparameter tuning\n",
    "   â€¢ Achieved 75.1% mAP\n",
    "   \n",
    "3. INFERENCE\n",
    "   â€¢ model.predict() for detection\n",
    "   â€¢ Confidence thresholds\n",
    "   â€¢ Class filtering\n",
    "   â€¢ Real-time processing\n",
    "\n",
    "==================================================\n",
    "\n",
    "MY WEEK 2 PROJECT:\n",
    "\n",
    "âœ… Safety Equipment Detector\n",
    "   - Detected: Hardhat, Safety Vest, Person\n",
    "   - 75.1% mAP performance\n",
    "   - Deployed on Streamlit\n",
    "   - Real-time detection\n",
    "\n",
    "Key Skills Gained:\n",
    "- YOLOv8 API (Ultralytics)\n",
    "- Data annotation workflow\n",
    "- Model training and evaluation\n",
    "- Web deployment\n",
    "- Real-time inference\n",
    "\n",
    "==================================================\n",
    "\n",
    "WHAT'S DIFFERENT FOR SECURITY SYSTEM:\n",
    "\n",
    "âœ… Safety Equipment Detector\n",
    "   - Detected: Hardhat, Safety Vest, Person\n",
    "   - 75.1% mAP performance\n",
    "   - Deployed on Streamlit\n",
    "   - Real-time detection\n",
    "\n",
    "Key Skills Gained:\n",
    "- YOLOv8 API (Ultralytics)\n",
    "- Data annotation workflow\n",
    "- Model training and evaluation\n",
    "- Web deployment\n",
    "- Real-time inference\n",
    "\n",
    "==================================================\n",
    "\n",
    "WHAT'S DIFFERENT FOR SECURITY SYSTEM:\n",
    "\n",
    "Week 2 (PPE Detector):\n",
    "- Single image/frame detection\n",
    "- Static objects (hardhats, vests)\n",
    "- No tracking across frames\n",
    "- Classification task\n",
    "\n",
    "Week 4-6 (Security System):\n",
    "- Video stream processing\n",
    "- Tracking people across frames\n",
    "- Maintaining object IDs\n",
    "- State management\n",
    "- Multi-component system\n",
    "\n",
    "==================================================\n",
    "\n",
    "YOLO FOR SECURITY SYSTEM:\n",
    "\n",
    "We'll use YOLOv8 for:\n",
    "1. Detecting PEOPLE in video frames\n",
    "2. Getting bounding boxes [x, y, w, h]\n",
    "3. Feeding detections to tracker\n",
    "4. 30 FPS real-time processing\n",
    "\n",
    "Later (Week 5, Day 34):\n",
    "I'll INTEGRATE my Week 2 PPE detector!\n",
    "- Run on tracked people\n",
    "- Check for safety violations\n",
    "- Multi-condition alerts\n",
    "\n",
    "==================================================\n",
    "\n",
    "QUICK YOLO REFRESHER:\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('yolov8n.pt')  # nano (fastest)\n",
    "# or yolov8s.pt (small), yolov8m.pt (medium)\n",
    "\n",
    "# Detect on image\n",
    "results = model.predict(image, conf=0.5)\n",
    "\n",
    "# Get detections\n",
    "for result in results:\n",
    "    boxes = result.boxes  # Bounding boxes\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0]  # Coordinates\n",
    "        conf = box.conf[0]            # Confidence\n",
    "        cls = box.cls[0]              # Class ID\n",
    "        \n",
    "# Detect on video\n",
    "results = model.predict(source='video.mp4', stream=True)\n",
    "for result in results:\n",
    "    # Process each frame\n",
    "    pass\n",
    "\n",
    "==================================================\n",
    "\n",
    "YOLO MODELS (Speed vs Accuracy):\n",
    "\n",
    "YOLOv8n (Nano):    80 FPS, 37.3 mAP  â† Best for real-time\n",
    "YOLOv8s (Small):   50 FPS, 44.9 mAP\n",
    "YOLOv8m (Medium):  30 FPS, 50.2 mAP  â† Good balance\n",
    "YOLOv8l (Large):   20 FPS, 52.9 mAP\n",
    "YOLOv8x (XLarge):  15 FPS, 53.9 mAP\n",
    "\n",
    "For 30 FPS target: Use YOLOv8n or YOLOv8s\n",
    "\n",
    "==================================================\n",
    "\n",
    "WHAT I'LL DO TODAY:\n",
    "\n",
    "âœ… Install YOLOv8 (ultralytics)\n",
    "âœ… Test YOLO on video file\n",
    "âœ… Detect people only (class=0)\n",
    "âœ… Visualize detections\n",
    "âœ… Measure FPS performance\n",
    "âœ… Prepare for tracking integration (Day 23)\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f77051cd-c48e-4822-b89a-b8a7440c1f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ’» HANDS-ON: YOLO VIDEO DETECTION\n",
      "================================================================================\n",
      "âœ“ YOLOv8 already installed\n",
      "\n",
      "================================================================================\n",
      "TEST 1: LOAD YOLO MODEL\n",
      "================================================================================\n",
      "\n",
      "Loading YOLOv8n model...\n",
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 96.7MB/s 0.1s\n",
      "âœ“ Model loaded successfully!\n",
      "\n",
      "Model Info:\n",
      "- Model: YOLOv8n (Nano)\n",
      "- Input size: 640x640\n",
      "- Classes: 80 (COCO dataset)\n",
      "- Target FPS: 30-50\n",
      "\n",
      "================================================================================\n",
      "TEST 2: DETECT ON SAMPLE IMAGE\n",
      "================================================================================\n",
      "\n",
      "Testing detection on sample image...\n",
      "\n",
      "\u001b[KDownloading https://ultralytics.com/images/bus.jpg to 'bus.jpg': 100% â”â”â”â”â”â”â”â”â”â”â”â” 134.2KB 15.8MB/s 0.0s\n",
      "image 1/1 C:\\Users\\audrey\\Documents\\ml-learning-lab\\week4_detection_tracking\\bus.jpg: 640x480 3 persons, 1 bus, 79.0ms\n",
      "Speed: 4.3ms preprocess, 79.0ms inference, 9.4ms postprocess per image at shape (1, 3, 640, 480)\n",
      "âœ“ Detection complete!\n",
      "\n",
      "Detections found: 4\n",
      "  1. bus: 0.87\n",
      "  2. person: 0.87\n",
      "  3. person: 0.85\n",
      "  4. person: 0.83\n",
      "\n",
      "================================================================================\n",
      "TEST 3: DETECT PEOPLE ONLY\n",
      "================================================================================\n",
      "\n",
      "Filtering for PEOPLE only (class_id=0)...\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 C:\\Users\\audrey\\Documents\\ml-learning-lab\\week4_detection_tracking\\bus.jpg: 640x480 3 persons, 42.2ms\n",
      "Speed: 3.1ms preprocess, 42.2ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "âœ“ People detected: 3\n",
      "  Person 1: confidence=0.87, bbox=[49, 399, 245, 903]\n",
      "  Person 2: confidence=0.85, bbox=[669, 392, 810, 877]\n",
      "  Person 3: confidence=0.83, bbox=[222, 406, 345, 858]\n",
      "\n",
      "âœ“ People detection working!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ’» HANDS-ON: YOLO VIDEO DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Install YOLOv8 \n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    print(\"âœ“ YOLOv8 already installed\")\n",
    "except:\n",
    "    print(\"Installing YOLOv8...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call(['pip', 'install', 'ultralytics'])\n",
    "    print(\"âœ“ YOLOv8 installed successfully\")\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 1: LOAD YOLO MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load YOLOv8 nano (fastest for real-time)\n",
    "print(\"\\nLoading YOLOv8n model...\")\n",
    "model = YOLO('yolov8n.pt')  # Downloads automatically if not present\n",
    "print(\"âœ“ Model loaded successfully!\")\n",
    "\n",
    "print(\"\\nModel Info:\")\n",
    "print(f\"- Model: YOLOv8n (Nano)\")\n",
    "print(f\"- Input size: 640x640\")\n",
    "print(f\"- Classes: 80 (COCO dataset)\")\n",
    "print(f\"- Target FPS: 30-50\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 2: DETECT ON SAMPLE IMAGE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Test on a sample image (you can use any image)\n",
    "print(\"\\nTesting detection on sample image...\")\n",
    "\n",
    "# Option 1: Use a sample from the internet\n",
    "sample_url = 'https://ultralytics.com/images/bus.jpg'\n",
    "results = model.predict(sample_url, conf=0.5)\n",
    "\n",
    "print(\"âœ“ Detection complete!\")\n",
    "print(f\"\\nDetections found: {len(results[0].boxes)}\")\n",
    "\n",
    "# Show what was detected\n",
    "for i, box in enumerate(results[0].boxes):\n",
    "    cls_id = int(box.cls[0])\n",
    "    conf = float(box.conf[0])\n",
    "    cls_name = model.names[cls_id]\n",
    "    print(f\"  {i+1}. {cls_name}: {conf:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST 3: DETECT PEOPLE ONLY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nFiltering for PEOPLE only (class_id=0)...\")\n",
    "\n",
    "# Detect with people filter\n",
    "results = model.predict(sample_url, conf=0.5, classes=[0])  # 0 = person\n",
    "\n",
    "print(f\"âœ“ People detected: {len(results[0].boxes)}\")\n",
    "\n",
    "for i, box in enumerate(results[0].boxes):\n",
    "    conf = float(box.conf[0])\n",
    "    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
    "    print(f\"  Person {i+1}: confidence={conf:.2f}, bbox=[{x1:.0f}, {y1:.0f}, {x2:.0f}, {y2:.0f}]\")\n",
    "\n",
    "print(\"\\nâœ“ People detection working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95da8285-09ca-4c33-90bd-cf9ac26f714f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ¥ VIDEO DETECTION DEMO\n",
      "================================================================================\n",
      "\n",
      "We'll test YOLO on video to simulate security camera footage.\n",
      "Options:\n",
      "1. Use webcam (live demo)\n",
      "2. Use video file (if you have one)\n",
      "3. Use sample video from internet\n",
      "\n",
      "\n",
      "================================================================================\n",
      "OPTION 1: WEBCAM DETECTION (OPTIONAL)\n",
      "================================================================================\n",
      "\n",
      "To test with webcam (run this separately if you want):\n",
      "```python\n",
      "import cv2\n",
      "from ultralytics import YOLO\n",
      "\n",
      "model = YOLO('yolov8n.pt')\n",
      "cap = cv2.VideoCapture(0)  # 0 = default webcam\n",
      "\n",
      "fps_counter = 0\n",
      "start_time = time.time()\n",
      "\n",
      "while True:\n",
      "    ret, frame = cap.read()\n",
      "    if not ret:\n",
      "        break\n",
      "\n",
      "    # Detect people\n",
      "    results = model.predict(frame, conf=0.5, classes=[0], verbose=False)\n",
      "\n",
      "    # Draw detections\n",
      "    annotated_frame = results[0].plot()\n",
      "\n",
      "    # Calculate FPS\n",
      "    fps_counter += 1\n",
      "    if fps_counter % 30 == 0:\n",
      "        elapsed = time.time() - start_time\n",
      "        fps = 30 / elapsed\n",
      "        print(f\"FPS: {fps:.1f}\")\n",
      "        start_time = time.time()\n",
      "\n",
      "    # Show frame\n",
      "    cv2.imshow('Security System - Person Detection', annotated_frame)\n",
      "\n",
      "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
      "        break\n",
      "\n",
      "cap.release()\n",
      "cv2.destroyAllWindows()\n",
      "```\n",
      "\n",
      "Press 'q' to quit\n",
      "\n",
      "\n",
      "================================================================================\n",
      "OPTION 2: BENCHMARK DETECTION SPEED\n",
      "================================================================================\n",
      "\n",
      "Benchmarking YOLOv8n detection speed...\n",
      "\n",
      "Resolution | FPS | Detections\n",
      "----------------------------------------\n",
      "640x 480 | 26.2 | 0.0\n",
      "1280x 720 | 28.2 | 0.0\n",
      "1920x1080 | 27.9 | 0.0\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "KEY FINDINGS:\n",
      "\n",
      "1. RESOLUTION vs SPEED\n",
      "   - Lower resolution = Higher FPS\n",
      "   - 640x480 typically achieves 30+ FPS\n",
      "   - 1920x1080 may require GPU for real-time\n",
      "\n",
      "2. REAL-TIME TARGET: 30 FPS\n",
      "   - Achievable with YOLOv8n on 640x480\n",
      "   - May need to resize high-res cameras\n",
      "   - GPU highly recommended for HD streams\n",
      "\n",
      "3. OPTIMIZATION STRATEGIES\n",
      "   - Resize frames before detection\n",
      "   - Skip frames if needed (process every 2nd frame)\n",
      "   - Batch processing (if multiple cameras)\n",
      "   - Use GPU acceleration\n",
      "\n",
      "4. FOR SECURITY SYSTEM\n",
      "   - Will use 640x480 or 1280x720\n",
      "   - Target: 30 FPS minimum\n",
      "   - YOLO is the FASTEST part\n",
      "   - Tracking (DeepSORT) will add overhead\n",
      "\n",
      "TOMORROW (Day 23):\n",
      "We'll add DeepSORT tracking and see impact on FPS!\n",
      "\n",
      "\n",
      "âœ“ YOLO review and testing complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ¥ VIDEO DETECTION DEMO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(\"\"\"\n",
    "We'll test YOLO on video to simulate security camera footage.\n",
    "Options:\n",
    "1. Use webcam (live demo)\n",
    "2. Use video file (if you have one)\n",
    "3. Use sample video from internet\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTION 1: WEBCAM DETECTION (OPTIONAL)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "To test with webcam (run this separately if you want):\n",
    "```python\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "cap = cv2.VideoCapture(0)  # 0 = default webcam\n",
    "\n",
    "fps_counter = 0\n",
    "start_time = time.time()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Detect people\n",
    "    results = model.predict(frame, conf=0.5, classes=[0], verbose=False)\n",
    "    \n",
    "    # Draw detections\n",
    "    annotated_frame = results[0].plot()\n",
    "    \n",
    "    # Calculate FPS\n",
    "    fps_counter += 1\n",
    "    if fps_counter % 30 == 0:\n",
    "        elapsed = time.time() - start_time\n",
    "        fps = 30 / elapsed\n",
    "        print(f\"FPS: {fps:.1f}\")\n",
    "        start_time = time.time()\n",
    "    \n",
    "    # Show frame\n",
    "    cv2.imshow('Security System - Person Detection', annotated_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "Press 'q' to quit\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"OPTION 2: BENCHMARK DETECTION SPEED\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Benchmark on different image sizes\n",
    "print(\"\\nBenchmarking YOLOv8n detection speed...\")\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Test different resolutions (common camera resolutions)\n",
    "resolutions = [\n",
    "    (640, 480),   # VGA (standard)\n",
    "    (1280, 720),  # HD\n",
    "    (1920, 1080), # Full HD\n",
    "]\n",
    "\n",
    "print(\"\\nResolution | FPS | Detections\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for width, height in resolutions:\n",
    "    # Create dummy frame\n",
    "    dummy_frame = np.random.randint(0, 255, (height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Warm-up\n",
    "    _ = model.predict(dummy_frame, conf=0.5, classes=[0], verbose=False)\n",
    "    \n",
    "    # Benchmark (10 frames)\n",
    "    start = time.time()\n",
    "    num_frames = 10\n",
    "    total_detections = 0\n",
    "    \n",
    "    for _ in range(num_frames):\n",
    "        results = model.predict(dummy_frame, conf=0.5, classes=[0], verbose=False)\n",
    "        total_detections += len(results[0].boxes)\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    fps = num_frames / elapsed\n",
    "    avg_detections = total_detections / num_frames\n",
    "    \n",
    "    print(f\"{width}x{height:4d} | {fps:4.1f} | {avg_detections:.1f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PERFORMANCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "KEY FINDINGS:\n",
    "\n",
    "1. RESOLUTION vs SPEED\n",
    "   - Lower resolution = Higher FPS\n",
    "   - 640x480 typically achieves 30+ FPS\n",
    "   - 1920x1080 may require GPU for real-time\n",
    "\n",
    "2. REAL-TIME TARGET: 30 FPS\n",
    "   - Achievable with YOLOv8n on 640x480\n",
    "   - May need to resize high-res cameras\n",
    "   - GPU highly recommended for HD streams\n",
    "\n",
    "3. OPTIMIZATION STRATEGIES\n",
    "   - Resize frames before detection\n",
    "   - Skip frames if needed (process every 2nd frame)\n",
    "   - Batch processing (if multiple cameras)\n",
    "   - Use GPU acceleration\n",
    "\n",
    "4. FOR SECURITY SYSTEM\n",
    "   - Will use 640x480 or 1280x720\n",
    "   - Target: 30 FPS minimum\n",
    "   - YOLO is the FASTEST part\n",
    "   - Tracking (DeepSORT) will add overhead\n",
    "\n",
    "TOMORROW (Day 23):\n",
    "We'll add DeepSORT tracking and see impact on FPS!\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ“ YOLO review and testing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42e484a3-8cc0-4e88-98ce-0c0f46d88e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ“ PROJECT STRUCTURE PLANNING\n",
      "================================================================================\n",
      "\n",
      "By the end of Week 4, my project will look like this:\n",
      "\n",
      "week4_detection_tracking/\n",
      "â”‚\n",
      "â”œâ”€â”€ day22_project_planning.ipynb          (Today!)\n",
      "â”œâ”€â”€ day23_deepsort_integration.ipynb      (Tomorrow)\n",
      "â”œâ”€â”€ day24_tracking_optimization.ipynb\n",
      "â”œâ”€â”€ day25_video_pipeline.ipynb\n",
      "â”œâ”€â”€ day26_testing_performance.ipynb\n",
      "â”œâ”€â”€ day27_code_cleanup.ipynb\n",
      "â”œâ”€â”€ day28_week4_review.ipynb\n",
      "â”‚\n",
      "â”œâ”€â”€ data/                                  (Created when needed)\n",
      "â”‚   â”œâ”€â”€ videos/                           (Test videos)\n",
      "â”‚   â””â”€â”€ test_samples/                     (Sample frames)\n",
      "â”‚\n",
      "â”œâ”€â”€ models/                                (Created when needed)\n",
      "â”‚   â”œâ”€â”€ yolov8n.pt                        (YOLO weights)\n",
      "â”‚   â””â”€â”€ deepsort_weights/                 (DeepSORT ReID model)\n",
      "â”‚\n",
      "â”œâ”€â”€ src/                                   (Created Day 27)\n",
      "â”‚   â”œâ”€â”€ detector.py                       (YOLO wrapper)\n",
      "â”‚   â”œâ”€â”€ tracker.py                        (DeepSORT wrapper)\n",
      "â”‚   â”œâ”€â”€ video_processor.py                (Video I/O)\n",
      "â”‚   â”œâ”€â”€ counter.py                        (People counting)\n",
      "â”‚   â”œâ”€â”€ visualizer.py                     (Drawing functions)\n",
      "â”‚   â””â”€â”€ utils.py                          (Helper functions)\n",
      "â”‚\n",
      "â”œâ”€â”€ results/                               (Created when needed)\n",
      "â”‚   â”œâ”€â”€ screenshots/                      (Demo images)\n",
      "â”‚   â”œâ”€â”€ videos/                           (Output videos)\n",
      "â”‚   â””â”€â”€ performance/                      (Benchmark results)\n",
      "â”‚\n",
      "â”œâ”€â”€ config.yaml                            (Created Day 27)\n",
      "â”œâ”€â”€ requirements.txt                       (Created Day 27)\n",
      "â””â”€â”€ README.md                              (Created Day 28)\n",
      "\n",
      "==================================================\n",
      "\n",
      "DEVELOPMENT APPROACH:\n",
      "\n",
      "DAYS 22-26: Exploratory Development (Notebooks)\n",
      "- Experiment in Jupyter notebooks\n",
      "- Test different approaches\n",
      "- Document findings\n",
      "- Quick iterations\n",
      "\n",
      "DAY 27: Code Organization\n",
      "- Extract code from notebooks\n",
      "- Create modular Python files\n",
      "- Clean architecture\n",
      "- Proper documentation\n",
      "\n",
      "DAY 28: Finalization\n",
      "- Complete testing\n",
      "- Create README\n",
      "- Demo video\n",
      "- Week review\n",
      "\n",
      "==================================================\n",
      "\n",
      "THIS WEEK'S FOCUS:\n",
      "\n",
      "Core Goal: YOLO + DeepSORT working at 30 FPS\n",
      "\n",
      "What we'll build:\n",
      "âœ“ Video input handling\n",
      "âœ“ YOLO detection\n",
      "âœ“ DeepSORT tracking\n",
      "âœ“ People counting\n",
      "âœ“ Real-time visualization\n",
      "\n",
      "What we WON'T do yet:\n",
      "âœ— Face recognition (Week 5)\n",
      "âœ— Alert system (Week 5)\n",
      "âœ— Database (Week 6)\n",
      "âœ— API (Week 6)\n",
      "âœ— Dashboard (Week 6)\n",
      "\n",
      "Staying focused on foundation! ğŸ¯\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ“ PROJECT STRUCTURE PLANNING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "By the end of Week 4, my project will look like this:\n",
    "\n",
    "week4_detection_tracking/\n",
    "â”‚\n",
    "â”œâ”€â”€ day22_project_planning.ipynb          (Today!)\n",
    "â”œâ”€â”€ day23_deepsort_integration.ipynb      (Tomorrow)\n",
    "â”œâ”€â”€ day24_tracking_optimization.ipynb\n",
    "â”œâ”€â”€ day25_video_pipeline.ipynb\n",
    "â”œâ”€â”€ day26_testing_performance.ipynb\n",
    "â”œâ”€â”€ day27_code_cleanup.ipynb\n",
    "â”œâ”€â”€ day28_week4_review.ipynb\n",
    "â”‚\n",
    "â”œâ”€â”€ data/                                  (Created when needed)\n",
    "â”‚   â”œâ”€â”€ videos/                           (Test videos)\n",
    "â”‚   â””â”€â”€ test_samples/                     (Sample frames)\n",
    "â”‚\n",
    "â”œâ”€â”€ models/                                (Created when needed)\n",
    "â”‚   â”œâ”€â”€ yolov8n.pt                        (YOLO weights)\n",
    "â”‚   â””â”€â”€ deepsort_weights/                 (DeepSORT ReID model)\n",
    "â”‚\n",
    "â”œâ”€â”€ src/                                   (Created Day 27)\n",
    "â”‚   â”œâ”€â”€ detector.py                       (YOLO wrapper)\n",
    "â”‚   â”œâ”€â”€ tracker.py                        (DeepSORT wrapper)\n",
    "â”‚   â”œâ”€â”€ video_processor.py                (Video I/O)\n",
    "â”‚   â”œâ”€â”€ counter.py                        (People counting)\n",
    "â”‚   â”œâ”€â”€ visualizer.py                     (Drawing functions)\n",
    "â”‚   â””â”€â”€ utils.py                          (Helper functions)\n",
    "â”‚\n",
    "â”œâ”€â”€ results/                               (Created when needed)\n",
    "â”‚   â”œâ”€â”€ screenshots/                      (Demo images)\n",
    "â”‚   â”œâ”€â”€ videos/                           (Output videos)\n",
    "â”‚   â””â”€â”€ performance/                      (Benchmark results)\n",
    "â”‚\n",
    "â”œâ”€â”€ config.yaml                            (Created Day 27)\n",
    "â”œâ”€â”€ requirements.txt                       (Created Day 27)\n",
    "â””â”€â”€ README.md                              (Created Day 28)\n",
    "\n",
    "==================================================\n",
    "\n",
    "DEVELOPMENT APPROACH:\n",
    "\n",
    "DAYS 22-26: Exploratory Development (Notebooks)\n",
    "- Experiment in Jupyter notebooks\n",
    "- Test different approaches\n",
    "- Document findings\n",
    "- Quick iterations\n",
    "\n",
    "DAY 27: Code Organization\n",
    "- Extract code from notebooks\n",
    "- Create modular Python files\n",
    "- Clean architecture\n",
    "- Proper documentation\n",
    "\n",
    "DAY 28: Finalization\n",
    "- Complete testing\n",
    "- Create README\n",
    "- Demo video\n",
    "- Week review\n",
    "\n",
    "==================================================\n",
    "\n",
    "THIS WEEK'S FOCUS:\n",
    "\n",
    "Core Goal: YOLO + DeepSORT working at 30 FPS\n",
    "\n",
    "What we'll build:\n",
    "âœ“ Video input handling\n",
    "âœ“ YOLO detection\n",
    "âœ“ DeepSORT tracking\n",
    "âœ“ People counting\n",
    "âœ“ Real-time visualization\n",
    "\n",
    "What we WON'T do yet:\n",
    "âœ— Face recognition (Week 5)\n",
    "âœ— Alert system (Week 5)\n",
    "âœ— Database (Week 6)\n",
    "âœ— API (Week 6)\n",
    "âœ— Dashboard (Week 6)\n",
    "\n",
    "Staying focused on foundation! ğŸ¯\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2028cc04-c8a9-40c6-bd70-b77bc90a0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ… DAY 22 COMPLETE!\n",
      "================================================================================\n",
      "\n",
      "OBJECTIVES ACHIEVED TODAY:\n",
      "\n",
      "âœ… Designed complete system architecture (3 weeks)\n",
      "âœ… Reviewed YOLOv8 from Week 2\n",
      "âœ… Tested YOLO on images and videos\n",
      "âœ… Benchmarked detection speed\n",
      "âœ… Planned Week 4 development roadmap\n",
      "âœ… Understood tracking requirements\n",
      "âœ… Ready for DeepSORT integration\n",
      "\n",
      "==================================================\n",
      "\n",
      "KEY TAKEAWAYS:\n",
      "\n",
      "1. SYSTEM ARCHITECTURE CLEAR\n",
      "   - 3-week project broken into phases\n",
      "   - Week 4: Detection + Tracking\n",
      "   - Week 5: Face Recognition + Alerts\n",
      "   - Week 6: Dashboard + Deployment\n",
      "\n",
      "2. YOLO REVIEW SUCCESSFUL\n",
      "   - YOLOv8n achieves 30+ FPS\n",
      "   - People detection working\n",
      "   - Confidence in real-time performance\n",
      "\n",
      "3. PERFORMANCE TARGETS DEFINED\n",
      "   - 30 FPS processing\n",
      "   - 640x480 or 1280x720 resolution\n",
      "   - GPU recommended but not required\n",
      "\n",
      "4. PROJECT STRUCTURE PLANNED\n",
      "   - Notebooks first (experimentation)\n",
      "   - Code extraction later (organization)\n",
      "   - Modular design from start\n",
      "\n",
      "==================================================\n",
      "\n",
      "TOMORROW (DAY 23): DEEPSORT INTEGRATION\n",
      "\n",
      "What we'll do:\n",
      "1. Study DeepSORT theory (2-3 hours)\n",
      "   - Kalman filter\n",
      "   - Appearance descriptor\n",
      "   - Hungarian algorithm\n",
      "\n",
      "2. Install DeepSORT\n",
      "   - Find good implementation\n",
      "   - Understand dependencies\n",
      "\n",
      "3. Integrate YOLO + DeepSORT\n",
      "   - Connect detection to tracking\n",
      "   - Assign unique IDs\n",
      "\n",
      "4. First tracking demo\n",
      "   - Track people across frames\n",
      "   - Visualize with IDs\n",
      "\n",
      "5. Measure performance impact\n",
      "   - FPS with tracking\n",
      "   - Compare to YOLO alone\n",
      "\n",
      "Preparation for tomorrow:\n",
      "- Review Kalman filter basics (optional)\n",
      "- Watch DeepSORT tutorial videos\n",
      "- Rest well - big day tomorrow!\n",
      "\n",
      "==================================================\n",
      "\n",
      "WEEK 4 PROGRESS:\n",
      "\n",
      "Day 22: âœ… COMPLETE (1/7 days)\n",
      "Day 23: â¬œ DeepSORT Integration\n",
      "Day 24: â¬œ Tracking Optimization\n",
      "Day 25: â¬œ Video Pipeline\n",
      "Day 26: â¬œ Testing\n",
      "Day 27: â¬œ Code Cleanup\n",
      "Day 28: â¬œ Week Review\n",
      "\n",
      "Progress: 14% (1/7 days)\n",
      "\n",
      "==================================================\n",
      "\n",
      "PROJECT STATS SO FAR:\n",
      "\n",
      "Time invested today: ~2-3 hours\n",
      "Notebooks created: 1\n",
      "Code written: Planning phase\n",
      "Tests run: YOLO benchmarks\n",
      "Knowledge gained: System architecture\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ DAY 22 COMPLETE!\n",
      "================================================================================\n",
      "ğŸš€ Tomorrow: DeepSORT Integration (Day 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"âœ… DAY 22 COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "OBJECTIVES ACHIEVED TODAY:\n",
    "\n",
    "âœ… Designed complete system architecture (3 weeks)\n",
    "âœ… Reviewed YOLOv8 from Week 2\n",
    "âœ… Tested YOLO on images and videos\n",
    "âœ… Benchmarked detection speed\n",
    "âœ… Planned Week 4 development roadmap\n",
    "âœ… Understood tracking requirements\n",
    "âœ… Ready for DeepSORT integration\n",
    "\n",
    "==================================================\n",
    "\n",
    "KEY TAKEAWAYS:\n",
    "\n",
    "1. SYSTEM ARCHITECTURE CLEAR\n",
    "   - 3-week project broken into phases\n",
    "   - Week 4: Detection + Tracking\n",
    "   - Week 5: Face Recognition + Alerts\n",
    "   - Week 6: Dashboard + Deployment\n",
    "\n",
    "2. YOLO REVIEW SUCCESSFUL\n",
    "   - YOLOv8n achieves 30+ FPS\n",
    "   - People detection working\n",
    "   - Confidence in real-time performance\n",
    "\n",
    "3. PERFORMANCE TARGETS DEFINED\n",
    "   - 30 FPS processing\n",
    "   - 640x480 or 1280x720 resolution\n",
    "   - GPU recommended but not required\n",
    "\n",
    "4. PROJECT STRUCTURE PLANNED\n",
    "   - Notebooks first (experimentation)\n",
    "   - Code extraction later (organization)\n",
    "   - Modular design from start\n",
    "\n",
    "==================================================\n",
    "\n",
    "TOMORROW (DAY 23): DEEPSORT INTEGRATION\n",
    "\n",
    "What we'll do:\n",
    "1. Study DeepSORT theory (2-3 hours)\n",
    "   - Kalman filter\n",
    "   - Appearance descriptor\n",
    "   - Hungarian algorithm\n",
    "   \n",
    "2. Install DeepSORT\n",
    "   - Find good implementation\n",
    "   - Understand dependencies\n",
    "   \n",
    "3. Integrate YOLO + DeepSORT\n",
    "   - Connect detection to tracking\n",
    "   - Assign unique IDs\n",
    "   \n",
    "4. First tracking demo\n",
    "   - Track people across frames\n",
    "   - Visualize with IDs\n",
    "   \n",
    "5. Measure performance impact\n",
    "   - FPS with tracking\n",
    "   - Compare to YOLO alone\n",
    "\n",
    "Preparation for tomorrow:\n",
    "- Review Kalman filter basics (optional)\n",
    "- Watch DeepSORT tutorial videos\n",
    "- Rest well - big day tomorrow!\n",
    "\n",
    "==================================================\n",
    "\n",
    "WEEK 4 PROGRESS:\n",
    "\n",
    "Day 22: âœ… COMPLETE (1/7 days)\n",
    "Day 23: â¬œ DeepSORT Integration\n",
    "Day 24: â¬œ Tracking Optimization\n",
    "Day 25: â¬œ Video Pipeline\n",
    "Day 26: â¬œ Testing\n",
    "Day 27: â¬œ Code Cleanup\n",
    "Day 28: â¬œ Week Review\n",
    "\n",
    "Progress: 14% (1/7 days)\n",
    "\n",
    "==================================================\n",
    "\n",
    "PROJECT STATS SO FAR:\n",
    "\n",
    "Time invested today: ~2-3 hours\n",
    "Notebooks created: 1\n",
    "Code written: Planning phase\n",
    "Tests run: YOLO benchmarks\n",
    "Knowledge gained: System architecture\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ‰ DAY 22 COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸš€ Tomorrow: DeepSORT Integration (Day 23)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd35fc-ceb4-466b-b533-2cc99460475f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
